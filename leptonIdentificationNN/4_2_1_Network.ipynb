{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matplotlib is a matlab like plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# SciKitLearn is a useful machine learning utilities library\n",
    "import sklearn\n",
    "# The sklearn dataset module helps generating |datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79102, 1)\n"
     ]
    }
   ],
   "source": [
    "# importing dataset\n",
    "# import data\n",
    "from DataExtraction import dataNoMass as data\n",
    "from DataExtraction import dataWithP2\n",
    "from DataExtraction import dataWithP2E2 \n",
    "from DataExtraction import dataWithMass \n",
    "# from DataExtraction import p2E2 as data\n",
    "# from DataExtraction import p2NegE2 as data\n",
    "from DataExtraction import labels\n",
    "#from DataExtraction import labels2D as labels\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "labels = np.row_stack(labels)\n",
    "#labels = labels.T\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.73596191  0.8398658  -0.11143488 39.48083318]\n",
      "[1]\n",
      "[47.30611801  1.31948066 -0.59230787 94.81924115]\n",
      "[1]\n",
      "[151.81565857   0.9477132   -0.26961038 225.25115398]\n",
      "[0]\n",
      "[335.43484497  -0.39157015   0.69631833 361.48074898]\n",
      "[1]\n",
      "[32.45707321 -0.29633594  2.52936745 33.89280616]\n",
      "[1]\n",
      "label shape (79102, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79102"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any other data manipulations/printing here\n",
    "for i in range(5):\n",
    "    print(train_data[i])\n",
    "    print(labels[i])\n",
    "    \n",
    "print(\"label shape\", labels.shape)\n",
    "labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define softmax\n",
    "def softmax(z):\n",
    "    #Calculate exponent term first\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "\n",
    "# softmax loss\n",
    "def softmax_loss(y,y_hat):\n",
    "    # clipping value \n",
    "    minval = 0.000000000001\n",
    "    # number of samples\n",
    "    m = y.shape[0]\n",
    "    # loss formula, note that np.sum sums up the entire matrix and therefore does the job of two sums from the formula \n",
    "    loss = -1/m * np.sum(y * np.log(y_hat.clip(min=minval)))\n",
    "    return loss\n",
    "\n",
    "# crossentropy loss\n",
    "def crossEntropy_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    if y.all() == 1:\n",
    "        return -1/m * np.sum(np.log(y_hat))\n",
    "    else:\n",
    "        return -1/m * np.sum(np.log(1 - y_hat))\n",
    "\n",
    "# mse loss\n",
    "def mse_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    return np.sum((y_hat - y)**2) / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define derivatives\n",
    "\n",
    "# loss derivative\n",
    "def loss_derivative(y,y_hat):\n",
    "    return (y_hat-y)\n",
    "\n",
    "# tanh derivative\n",
    "def tanh_derivative(x):\n",
    "    return (1 - np.power(x, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propogation\n",
    "def forward_prop(model, a0):\n",
    "    \n",
    "    #Start Forward Propagation\n",
    "    \n",
    "    # Load parameters from model (1)\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    \n",
    "    # Do the first Linear step \n",
    "    # Z1 is the input layer x times the dot product of the weights + our bias b\n",
    "    z1 = a0.dot(W1) + b1\n",
    "    \n",
    "    # Put it through the first activation function\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    # Second linear step\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    # Second activation function\n",
    "    a2 = softmax(z2)\n",
    "    #print(\"a2 shape\", a2.shape)\n",
    "    #Store all results in these values\n",
    "    cache = {'a0':a0,'z1':z1,'a1':a1,'z2':z2,'a2':a2}\n",
    "    return cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the BACKWARD PROPAGATION function\n",
    "def backward_prop(model,cache,y):\n",
    "\n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    \n",
    "    # add weights to print list\n",
    "    w00.append(W1[0])\n",
    "    w01.append(W1[1])\n",
    "    w02.append(W1[2])\n",
    "    w03.append(W1[3])\n",
    "    w10.append(W1[0])\n",
    "    w11.append(W1[1])\n",
    "    \n",
    "    # Load forward propagation results\n",
    "    a0,a1,a2 = cache['a0'],cache['a1'],cache['a2']\n",
    "    #print(\"a2 shape in back prop\", a2.shape)\n",
    "    #print(\"a1 shape in back prop\", a1.shape)\n",
    "    # Get number of samples\n",
    "    m = y.shape[0]\n",
    "    #print(\"m shape\", m)\n",
    "    # Calculate loss derivative with respect to output\n",
    "    dz2 = loss_derivative(y=y,y_hat=a2)\n",
    "    #print(\"y shape\", y.shape)\n",
    "    #print(\"dz2 shape\", dz2.shape)\n",
    "    # Calculate loss derivative with respect to second layer weights\n",
    "    dW2 = 1/m*(a1.T).dot(dz2) #dW2 = 1/m*(a1.T).dot(dz2) \n",
    "    #print(\"dW2 shape\", dW2.shape)\n",
    "    # Calculate loss derivative with respect to second layer bias\n",
    "    db2 = 1/m*np.sum(dz2, axis=0)\n",
    "    \n",
    "    dz1 = np.multiply(dz2.dot(W2.T),tanh_derivative(a1))\n",
    "    \n",
    "    dW1 = 1/m*np.dot(a0.T,dz1)\n",
    "    \n",
    "    db1 = 1/m*np.sum(dz1,axis=0)\n",
    "    \n",
    "    # Store gradients\n",
    "    grads = {'dW2':dW2,'db2':db2,'dW1':dW1,'db1':db1}\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING PHASE\n",
    "def initialize_parameters(nn_input_dim,nn_hdim,nn_output_dim):\n",
    "    # First layer weights\n",
    "    W1 = 2 *np.random.randn(nn_input_dim, nn_hdim) - 1\n",
    "    \n",
    "    # First layer bias\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    \n",
    "    # Second layer weights\n",
    "    W2 = 2 * np.random.rand(nn_hdim, nn_output_dim)\n",
    "    b2 = np.zeros((1,nn_output_dim))\n",
    "    \n",
    "    \n",
    "    # Package and return model\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "    return model\n",
    "def update_parameters(model,grads,learning_rate):\n",
    "    # Load parameters\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    \n",
    "    # Update parameters\n",
    "    W1 -= learning_rate * grads['dW1']\n",
    "    b1 -= learning_rate * grads['db1']\n",
    "    W2 -= learning_rate * grads['dW2']\n",
    "    b2 -= learning_rate * grads['db2']\n",
    "#     W1 = learning_rate * W1# * grads['dW1']\n",
    "#     b1 = learning_rate * b1\n",
    "#     W2 = learning_rate * W2\n",
    "#     b2 = learning_rate * b2\n",
    "\n",
    "    \n",
    "    # Store and return parameters\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "    return model\n",
    "def predict(model, x):\n",
    "    # Do forward pass\n",
    "    c = forward_prop(model,x)\n",
    "    #get y_hat\n",
    "    y_hat = c['a2']\n",
    "    # plotArr.append([x, y_hat]) #added to make plot\n",
    "    return y_hat\n",
    "def calc_accuracy(model,x,y):\n",
    "    # Get total number of examples\n",
    "    m = y.shape[0]\n",
    "    # Do a prediction with the model\n",
    "    pred = predict(model,x)\n",
    "    # Ensure prediction and truth vector y have the same shape\n",
    "    pred = pred.reshape(y.shape)\n",
    "    # Calculate the number of wrong examples\n",
    "    error = np.sum(np.abs(pred-y))\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100\n",
    "def train(model,X_,y_,learning_rate, epochs=2001, print_loss=False):\n",
    "    # Gradient descent. Loop over epochs\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        # Forward propagation\n",
    "        cache = forward_prop(model,X_)\n",
    "        #a1, probs = cache['a1'],cache['a2']\n",
    "        # Backpropagation\n",
    "        \n",
    "        grads = backward_prop(model,cache,y_)\n",
    "        # Gradient descent parameter update\n",
    "        # Assign new parameters to the model\n",
    "        model = update_parameters(model=model,grads=grads,learning_rate=learning_rate)\n",
    "    \n",
    "        a2 = cache['a2']\n",
    "        thisLoss = mse_loss(y_,a2) # set loss function here\n",
    "        losses.append(thisLoss)\n",
    "        y_hat = predict(model,X_) # getting rid of this because it's wrong\n",
    "        y_true = y_.argmax(axis=1)\n",
    "        accur = accuracy_score(a2,train_labels)\n",
    "        train_accuracies.append(accur)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            placeholderVar = accuracy_score(a2, train_labels)\n",
    "            test_accuracy = accuracyOfModel(model, test_data, test_labels)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "            test_num.append(i)\n",
    "        #Printing loss & accuracy every 100 iterations\n",
    "        if print_loss and i % 300==0:\n",
    "            print('Loss after iteration',i,':',thisLoss)\n",
    "            print('Train Accuracy after iteration',i,':',accur*100,'%')\n",
    "            print('Test Accuracy after iteration',i,':',test_accuracy*100,'%')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING PHASE\n",
    "# test the accuracy of any model\n",
    "def accuracyOfModel(_model, _testData, _testLabels):\n",
    "    y_pred = predict(_model,_testData) # make predictions on test data\n",
    "    y_true = _testLabels # get usable info from labels\n",
    "    return accuracy_score(y_pred, y_true)\n",
    "\n",
    "def accuracy_score(_outputNodes, _labels):\n",
    "    for i in range(len(_outputNodes)-1):\n",
    "        if _outputNodes[i]>.5:\n",
    "            _outputNodes[i]=[1]\n",
    "        else:\n",
    "            _outputNodes[i]=[0]\n",
    "    numWrong = np.count_nonzero(np.subtract(_outputNodes,_labels))/2\n",
    "    return (len(_outputNodes)-numWrong)/len(_outputNodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 0.49996207428383604\n",
      "Train Accuracy after iteration 0 : 75.0018962858082 %\n",
      "Test Accuracy after iteration 0 : 74.78319132259614 %\n",
      "Loss after iteration 300 : 0.49996207428383604\n",
      "Train Accuracy after iteration 300 : 75.0018962858082 %\n",
      "Test Accuracy after iteration 300 : 74.78319132259614 %\n",
      "Loss after iteration 600 : 0.49996207428383604\n",
      "Train Accuracy after iteration 600 : 75.0018962858082 %\n",
      "Test Accuracy after iteration 600 : 74.78319132259614 %\n",
      "Loss after iteration 900 : 0.49996207428383604\n",
      "Train Accuracy after iteration 900 : 75.0018962858082 %\n",
      "Test Accuracy after iteration 900 : 74.78319132259614 %\n",
      "Loss after iteration 1200 : 0.49996207428383604\n",
      "Train Accuracy after iteration 1200 : 75.0018962858082 %\n",
      "Test Accuracy after iteration 1200 : 74.78319132259614 %\n",
      "Loss after iteration 1500 : 0.49996207428383604\n",
      "Train Accuracy after iteration 1500 : 75.0018962858082 %\n",
      "Test Accuracy after iteration 1500 : 74.78319132259614 %\n",
      "Loss after iteration 1800 : 0.49996207428383604\n",
      "Train Accuracy after iteration 1800 : 75.0018962858082 %\n",
      "Test Accuracy after iteration 1800 : 74.78319132259614 %\n",
      "Loss after iteration 2100 : 0.49996207428383604\n",
      "Train Accuracy after iteration 2100 : 75.0018962858082 %\n",
      "Test Accuracy after iteration 2100 : 74.78319132259614 %\n"
     ]
    }
   ],
   "source": [
    "# plotArr = []\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "test_num = []\n",
    "w00 = []\n",
    "w01 = []\n",
    "w02 = []\n",
    "w03 = []\n",
    "w10 = []\n",
    "w11 = []\n",
    "learnRate = 0.07\n",
    "np.random.seed(0)\n",
    "# This is what we return at the end\n",
    "model = initialize_parameters(nn_input_dim=4, nn_hdim= 2, nn_output_dim= 1)\n",
    "model = train(model,train_data,train_labels,learning_rate=learnRate,epochs=2101,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight 1 [[ 2.52810469 -0.19968558]\n",
      " [ 0.95747597  3.4817864 ]\n",
      " [ 2.73511598 -2.95455576]\n",
      " [ 0.90017684 -1.30271442]]\n",
      "bias 1 [[ 0.00000000e+00 -1.96903547e-13]]\n",
      "weight 2 [[-71.60209674]\n",
      " [ 74.2963053 ]]\n",
      "bias 2 [[-73.52942226]]\n"
     ]
    }
   ],
   "source": [
    "print(\"weight 1\", model['W1'])\n",
    "print(\"bias 1\", model['b1'])\n",
    "print(\"weight 2\", model['W2'])\n",
    "print(\"bias 2\", model['b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x124f38940>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w00, label=\"W00\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.scatter(test_num, test_accuracies, label=\"Test Accuracy\", s=16, color=\"green\")\n",
    "#plt.plot(test_accuracies, label=\"Test Accuracy\")\n",
    "plt.plot()\n",
    "plt.legend()\n",
    "plt.title(\"Network Loss and Accuracy per Epoch with %1.3f Learning Rate\" %learnRate)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = forward_prop(model, test_data)\n",
    "testgrads = backward_prop(model,cache,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache a0 [[ 3.04954052e+01  1.73306084e+00 -1.82328641e+00  8.89655894e+01]\n",
      " [ 2.89854202e+01 -7.85819769e-01 -3.02078390e+00  3.84051155e+01]\n",
      " [ 1.25733505e+02 -1.58720958e+00 -1.75277555e+00  3.20279714e+02]\n",
      " ...\n",
      " [ 2.29264641e+01 -7.84133911e-01  4.91462834e-02  3.03434493e+01]\n",
      " [ 4.72479477e+01  4.24064606e-01 -1.08015470e-01  5.15604216e+01]\n",
      " [ 3.28610115e+01  6.34800732e-01  1.06677556e+00  3.97075345e+01]]\n",
      "cache a1 [[ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " ...\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]\n",
      " [ 1. -1.]]\n",
      "cache z1 [[ 153.85280391 -110.56509958]\n",
      " [  98.83497431  -49.62985025]\n",
      " [ 599.86208452 -442.68782094]\n",
      " ...\n",
      " [  84.65860299  -46.98232545]\n",
      " [ 165.97185225  -74.80759849]\n",
      " [ 122.34544144  -59.23105523]]\n",
      "cache a2 [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "cache z2 [[-219.42782431]\n",
      " [-219.42782431]\n",
      " [-219.42782431]\n",
      " ...\n",
      " [-219.42782431]\n",
      " [-219.42782431]\n",
      " [-219.42782431]]\n"
     ]
    }
   ],
   "source": [
    "print(\"cache a0\", cache['a0'])\n",
    "print(\"cache a1\", cache['a1'])\n",
    "print(\"cache z1\", cache['z1'])\n",
    "print(\"cache a2\", cache['a2'])\n",
    "print(\"cache z2\", cache['z2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test grads dW2 [[ 0.49996207]\n",
      " [-0.49996207]]\n",
      "test grads db2 [0.49996207]\n",
      "test grads dW1 [[ 0.00000000e+00  2.21905169e-13]\n",
      " [ 0.00000000e+00  2.17623866e-15]\n",
      " [ 0.00000000e+00 -4.31867194e-14]\n",
      " [ 0.00000000e+00  2.26490913e-13]]\n",
      "test grads db1 [0.00000000e+00 1.41896446e-14]\n"
     ]
    }
   ],
   "source": [
    "print(\"test grads dW2\", testgrads['dW2'])\n",
    "print(\"test grads db2\", testgrads['db2'])\n",
    "print(\"test grads dW1\", testgrads['dW1'])\n",
    "print(\"test grads db1\", testgrads['db1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
