{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this has three hidden layers !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matplotlib is a matlab like plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# SciKitLearn is a useful machine learning utilities library\n",
    "import sklearn\n",
    "# The sklearn dataset module helps generating |datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "# import data\n",
    "from DataExtraction import dataNoMass as data\n",
    "from DataExtraction import dataWithP2\n",
    "from DataExtraction import dataWithP2E2 \n",
    "from DataExtraction import dataWithMass \n",
    "#from DataExtraction import p2E2 as data\n",
    "from DataExtraction import p2NegE2 \n",
    "#from DataExtraction import labels\n",
    "from DataExtraction import labels2D as labels\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any other data manipulations/printing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define softmax\n",
    "def softmax(z):\n",
    "    #Calculate exponent term first\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "\n",
    "# softmax loss\n",
    "def softmax_loss(y,y_hat):\n",
    "    # clipping value \n",
    "    minval = 0.000000000001\n",
    "    # number of samples\n",
    "    m = y.shape[0]\n",
    "    # loss formula, note that np.sum sums up the entire matrix and therefore does the job of two sums from the formula \n",
    "    loss = -1/m * np.sum(y * np.log(y_hat.clip(min=minval)))\n",
    "    return loss\n",
    "\n",
    "# crossentropy loss\n",
    "def crossEntropy_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    if y.all() == 1:\n",
    "        return -1/m * np.sum(np.log(y_hat))\n",
    "    else:\n",
    "        return -1/m * np.sum(np.log(1 - y_hat))\n",
    "\n",
    "# mse loss\n",
    "def mse_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    return np.sum((y_hat - y)**2) / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define derivatives\n",
    "\n",
    "# loss derivative\n",
    "def loss_derivative(y,y_hat):\n",
    "    return (y_hat-y)\n",
    "\n",
    "# tanh derivative\n",
    "def tanh_derivative(x):\n",
    "    return (1 - np.power(x, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propogation\n",
    "def forward_prop(model, a0):\n",
    "    \n",
    "    #Start Forward Propagation\n",
    "    \n",
    "    # Load parameters from model (1)\n",
    "    W1, b1, W2, b2, W3, b3, W4, b4 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3'], model['W4'], model['b4']\n",
    "    \n",
    "    # Do the first Linear step \n",
    "    # Z1 is the input layer x times the dot product of the weights + our bias b\n",
    "    z1 = a0.dot(W1) + b1\n",
    "    \n",
    "    # Put it through the first activation function\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    # Second linear step\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    # Second activation function\n",
    "    a2 = np.tanh(z2)\n",
    "    \n",
    "    # Third linear step\n",
    "    z3 = a2.dot(W3) + b3\n",
    "    \n",
    "    # Third activation function\n",
    "    a3 = np.tanh(z3)\n",
    "    \n",
    "    # Fourth linear step\n",
    "    z4 = a3.dot(W4) + b4\n",
    "    \n",
    "    # For the Third linear activation function we use the softmax function, \n",
    "    # either the sigmoid of softmax should be used for the last layer\n",
    "    a4 = softmax(z4)\n",
    "    \n",
    "    #Store all results in these values\n",
    "    cache = {'a0':a0,'z1':z1,'a1':a1,'z2':z2,'a2':a2,'a3':a3,'z3':z3,'a4':a4,'z4':z4}\n",
    "    return cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward propogation\n",
    "def backward_prop(model, cache, y):\n",
    "\n",
    "    # Load parameters from model (2)\n",
    "    W1, b1, W2, b2, W3, b3, W4, b4 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3'], model['W4'], model['b4']\n",
    "    \n",
    "    # Load forward propagation results\n",
    "    a0,a1,a2,a3,a4 = cache['a0'],cache['a1'],cache['a2'],cache['a3'],cache['a4']\n",
    "    \n",
    "    # Get number of samples\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    #calculate loss derivative with respect to output\n",
    "    \n",
    "    # Calculate loss derivative with respect to output\n",
    "    dz4 = loss_derivative(y=y,y_hat=a4)\n",
    "\n",
    "    # Calculate loss derivative with respect to third layer weights\n",
    "    dW4 = 1/m*(a3.T).dot(dz4) #dW2 = 1/m*(a1.T).dot(dz2) \n",
    "    \n",
    "    # Calculate loss derivative with respect to third layer bias\n",
    "    db4 = 1/m*np.sum(dz4, axis=0)\n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer\n",
    "    dz3 = np.multiply(dz4.dot(W4.T) ,tanh_derivative(a3))\n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer weights\n",
    "    dW3 = 1/m*np.dot(a2.T, dz3)\n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer bias\n",
    "    db3 = 1/m*np.sum(dz3, axis=0)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer\n",
    "    dz2 = np.multiply(dz3.dot(W3.T) ,tanh_derivative(a2))\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer weights\n",
    "    dW2 = 1/m*np.dot(a1.T, dz2)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer bias\n",
    "    db2 = 1/m*np.sum(dz2, axis=0)\n",
    "    \n",
    "    dz1 = np.multiply(dz2.dot(W2.T),tanh_derivative(a1))\n",
    "    \n",
    "    dW1 = 1/m*np.dot(a0.T,dz1)\n",
    "    \n",
    "    db1 = 1/m*np.sum(dz1,axis=0)\n",
    "    \n",
    "    # Store gradients\n",
    "    grads = {'dW4':dW4,'db4':db4, 'dW3':dW3, 'db3':db3, 'dW2':dW2,'db2':db2,'dW1':dW1,'db1':db1}\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PHASE\n",
    "# this takes in the number of nodes in each layer\n",
    "def initialize_parameters(input_dim, l1_dim, l2_dim, l3_dim, output_dim):\n",
    "    \n",
    "    # first layer weights\n",
    "    W1 = 2 * np.random.randn(input_dim, l1_dim) -1\n",
    "    # first layer bias\n",
    "    b1 = np.zeros((1,l1_dim))\n",
    "    \n",
    "    # second layer weights\n",
    "    W2 = 2 * np.random.randn(l1_dim, l2_dim) -1\n",
    "    # second layer bias\n",
    "    b2 = np.zeros((1, l2_dim))\n",
    "    \n",
    "    # third layer weights\n",
    "    W3 = 2 * np.random.randn(l2_dim, l3_dim) -1\n",
    "    # third layer bias\n",
    "    b3 = np.zeros((1, l3_dim))\n",
    "    \n",
    "    # fourth layer weights (output layer)\n",
    "    W4 = 2 * np.random.randn(l3_dim, output_dim)\n",
    "    # fourth layer bias (output layer)\n",
    "    b4 = np.zeros((1, output_dim))\n",
    "    \n",
    "    # package and return model\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2,'W3':W3,'b3':b3, 'W4':W4, 'b4':b4}\n",
    "    return model\n",
    "\n",
    "def update_parameters(model, grads, learning_rate):\n",
    "   # Load parameters from model (3)\n",
    "    W1, b1, W2, b2, W3, b3, W4, b4 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3'], model['W4'], model['b4']\n",
    "    \n",
    "    # update parameters\n",
    "    W1 -= learning_rate * grads['dW1']\n",
    "    b1 -= learning_rate * grads['db1']\n",
    "    W2 -= learning_rate * grads['dW2']\n",
    "    b2 -= learning_rate * grads['db2']\n",
    "    W3 -= learning_rate * grads['dW3']\n",
    "    b3 -= learning_rate * grads['db3']\n",
    "    W4 -= learning_rate * grads['dW4']\n",
    "    b4 -= learning_rate * grads['db4']\n",
    "    \n",
    "    # store and return parameters\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2,'W3':W3,'b3':b3, 'W4':W4, 'b4':b4}\n",
    "    return model\n",
    "\n",
    "# predict\n",
    "def predict(model, x):\n",
    "    # Do forward pass\n",
    "    c = forward_prop(model,x)\n",
    "    #get y_hat\n",
    "    y_hat = c['a4']\n",
    "    # plotArr.append([x, y_hat]) #added to make plot\n",
    "    return y_hat\n",
    "\n",
    "# calculate accuracy\n",
    "def calc_accuracy(model,x,y):\n",
    "    # Get total number of examples\n",
    "    m = y.shape[0]\n",
    "    # Do a prediction with the model\n",
    "    pred = predict(model,x)\n",
    "    # Ensure prediction and truth vector y have the same shape\n",
    "    pred = pred.reshape(y.shape)\n",
    "    # Calculate the number of wrong examples\n",
    "    error = np.sum(np.abs(pred-y))\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100\n",
    "\n",
    "# train\n",
    "# change numbner of epochs here\n",
    "def train(model,X_,y_,learning_rate, epochs=2001, print_loss=False):\n",
    "    # Gradient descent. Loop over epochs\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        # Forward propagation\n",
    "        cache = forward_prop(model,X_)\n",
    "        #a1, probs = cache['a1'],cache['a2']\n",
    "        # Backpropagation\n",
    "        \n",
    "        grads = backward_prop(model,cache,y_)\n",
    "        # Gradient descent parameter update\n",
    "        # Assign new parameters to the model\n",
    "        model = update_parameters(model=model,grads=grads,learning_rate=learning_rate)\n",
    "    \n",
    "        a4 = cache['a4'] \n",
    "        thisLoss = mse_loss(y_,a4) # set loss function here\n",
    "        losses.append(thisLoss)\n",
    "        y_hat = predict(model,X_) # getting rid of this because it's wrong\n",
    "        y_true = y_.argmax(axis=1)\n",
    "        accur = accuracy_score(a4,train_labels)\n",
    "        train_accuracies.append(accur)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            placeholderVar = accuracy_score(a4, train_labels)\n",
    "            test_accuracy = accuracyOfModel(model, test_data, test_labels)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "            test_num.append(i)\n",
    "        #Printing loss & accuracy every 100 iterations\n",
    "        if print_loss and i % 300==0:\n",
    "            print('Loss after iteration',i,':',thisLoss)\n",
    "            print('Train Accuracy after iteration',i,':',accur*100,'%')\n",
    "            print('Test Accuracy after iteration',i,':',test_accuracy*100,'%')\n",
    "    return model\n",
    "    \n",
    "# TESTING PHASE\n",
    "# test the accuracy of any model\n",
    "def accuracyOfModel(_model, _testData, _testLabels):\n",
    "    y_pred = predict(_model,_testData) # make predictions on test data\n",
    "    y_true = _testLabels # get usable info from labels\n",
    "    return accuracy_score(y_pred, y_true)\n",
    "\n",
    "def accuracy_score(_outputNodes, _labels):\n",
    "    for i in range(len(_outputNodes)-1):\n",
    "        if _outputNodes[i][0]>.5:\n",
    "            _outputNodes[i]=[1,0]\n",
    "        else:\n",
    "            _outputNodes[i]=[0,1]\n",
    "    numWrong = np.count_nonzero(np.subtract(_outputNodes,_labels))/2\n",
    "    return (len(_outputNodes)-numWrong)/len(_outputNodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 0.9761980112433126\n",
      "Train Accuracy after iteration 0 : 50.092285909332254 %\n",
      "Test Accuracy after iteration 0 : 49.65234760183055 %\n",
      "Loss after iteration 300 : 0.5007059327281751\n",
      "Train Accuracy after iteration 300 : 50.0644737174787 %\n",
      "Test Accuracy after iteration 300 : 49.67257465045132 %\n"
     ]
    }
   ],
   "source": [
    "# plotArr = []\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "test_num = []\n",
    "np.random.seed(0)\n",
    "learnRate = 0.06\n",
    "# This is what we return at the end\n",
    "model = initialize_parameters(input_dim=4, l1_dim=7, l2_dim=9, l3_dim=5, output_dim=2)\n",
    "model = train(model,train_data,train_labels,learning_rate=learnRate,epochs=301,print_loss=True) # original learning rate is 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.scatter(test_num, test_accuracies, label=\"Test Accuracy\", s=16, color=\"green\")\n",
    "plt.legend()\n",
    "plt.title(\"Network Loss and Accuracy per Epoch (Pt Eta Phi E) with %1.3f Learning Rate\" %learnRate)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
