{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matplotlib is a matlab like plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# SciKitLearn is a useful machine learning utilities library\n",
    "import sklearn\n",
    "# The sklearn dataset module helps generating |datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "# import data\n",
    "from DataExtraction import dataNoMass\n",
    "from DataExtraction import dataWithP2\n",
    "from DataExtraction import dataWithP2E2 \n",
    "from DataExtraction import dataWithMass \n",
    "from DataExtraction import p2E2 \n",
    "from DataExtraction import p2NegE2 as data\n",
    "#from DataExtraction import labels\n",
    "from DataExtraction import labels2D as labels\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normalize test data\n",
    "# train_data[:,0] = train_data[:,0] / np.linalg.norm(train_data[:,0]) # normalize column 0\n",
    "# train_data[:,1] = train_data[:,1] / np.linalg.norm(train_data[:,1]) # normalize column 1\n",
    "#normalize train data\n",
    "# test_data[:,0] = test_data[:,0] / np.linalg.norm(test_data[:,0]) # normalize column 0\n",
    "# test_data[:,1] = test_data[:,1] / np.linalg.norm(test_data[:,1]) # normalize column 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runSum = 0\n",
    "for e in train_data:\n",
    "    runSum+=e\n",
    "avgE2 = runSum/(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data/avgE2\n",
    "test_data = test_data/avgE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messing with the number of training data points\n",
    "# train_data = train_data[0:9]\n",
    "# train_labels = train_labels[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define all our functions\n",
    "\n",
    "def softmax(z):\n",
    "    #Calculate exponent term first\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "# loss functions\n",
    "def softmax_loss(y,y_hat):\n",
    "    # Clipping value\n",
    "    minval = 0.000000000001\n",
    "    # Number of samples\n",
    "    m = y.shape[0]\n",
    "    # Loss formula, note that np.sum sums up the entire matrix and therefore does the job of two sums from the formula\n",
    "    loss = -1/m * np.sum(y * np.log(y_hat.clip(min=minval)))\n",
    "    #loss = -1/m * np.sum(y * np.log(y_hat))\n",
    "    return loss\n",
    "\n",
    "def crossEntropy_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    if y.all() == 1:\n",
    "        return -1/m * np.sum(np.log(y_hat))\n",
    "    else:\n",
    "        return -1/m * np.sum(np.log(1 - y_hat))\n",
    "\n",
    "def mse_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    return np.sum((y_hat - y)**2) / m\n",
    "    \n",
    "def loss_derivative(y,y_hat):\n",
    "    return (y_hat-y)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return (1 - np.power(x, 2))\n",
    "\n",
    "# This is the forward propagation function\n",
    "def forward_prop(model,a0):\n",
    "    \n",
    "    #Start Forward Propagation\n",
    "    \n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2, W3, b3 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3']\n",
    "    \n",
    "    # Do the first Linear step \n",
    "    # Z1 is the input layer x times the dot product of the weights + our bias b\n",
    "    z1 = a0.dot(W1) + b1\n",
    "    \n",
    "    # Put it through the first activation function\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    # Second linear step\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    # Second activation function\n",
    "    a2 = np.tanh(z2)\n",
    "    \n",
    "    #Third linear step\n",
    "    z3 = a2.dot(W3) + b3\n",
    "    \n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    a3 = softmax(z3)\n",
    "    \n",
    "    #Store all results in these values\n",
    "    cache = {'a0':a0,'z1':z1,'a1':a1,'z2':z2,'a2':a2,'a3':a3,'z3':z3}\n",
    "    return cache\n",
    "\n",
    "# This is the BACKWARD PROPAGATION function\n",
    "def backward_prop(model,cache,y):\n",
    "\n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2, W3, b3 = model['W1'], model['b1'], model['W2'], model['b2'],model['W3'],model['b3']\n",
    "    # Load forward propagation results\n",
    "    a0,a1, a2,a3 = cache['a0'],cache['a1'],cache['a2'],cache['a3']\n",
    "    \n",
    "    # Get number of samples\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    # Calculate loss derivative with respect to output\n",
    "    dz3 = loss_derivative(y=y,y_hat=a3)\n",
    "\n",
    "    # Calculate loss derivative with respect to second layer weights\n",
    "    dW3 = 1/m*(a2.T).dot(dz3) #dW2 = 1/m*(a1.T).dot(dz2) \n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer bias\n",
    "    db3 = 1/m*np.sum(dz3, axis=0)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer\n",
    "    dz2 = np.multiply(dz3.dot(W3.T) ,tanh_derivative(a2))\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer weights\n",
    "    dW2 = 1/m*np.dot(a1.T, dz2)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer bias\n",
    "    db2 = 1/m*np.sum(dz2, axis=0)\n",
    "    \n",
    "    dz1 = np.multiply(dz2.dot(W2.T),tanh_derivative(a1))\n",
    "    \n",
    "    dW1 = 1/m*np.dot(a0.T,dz1)\n",
    "    \n",
    "    db1 = 1/m*np.sum(dz1,axis=0)\n",
    "    \n",
    "    # Store gradients\n",
    "    grads = {'dW3':dW3, 'db3':db3, 'dW2':dW2,'db2':db2,'dW1':dW1,'db1':db1}\n",
    "    return grads\n",
    "\n",
    "#TRAINING PHASE\n",
    "def initialize_parameters(nn_input_dim,nn_hdim,nn_output_dim):\n",
    "    # First layer weights\n",
    "    W1 = 2 *np.random.randn(nn_input_dim, nn_hdim) - 1\n",
    "    \n",
    "    # First layer bias\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    \n",
    "    # Second layer weights\n",
    "    W2 = 2 * np.random.randn(nn_hdim, nn_hdim) - 1\n",
    "    \n",
    "    # Second layer bias\n",
    "    b2 = np.zeros((1, nn_hdim))\n",
    "    W3 = 2 * np.random.rand(nn_hdim, nn_output_dim) - 1\n",
    "    b3 = np.zeros((1,nn_output_dim))\n",
    "    \n",
    "    \n",
    "    # Package and return model\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2,'W3':W3,'b3':b3}\n",
    "    return model\n",
    "\n",
    "def update_parameters(model,grads,learning_rate):\n",
    "    # Load parameters\n",
    "    W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "    \n",
    "    # Update parameters\n",
    "    W1 -= learning_rate * grads['dW1']\n",
    "    b1 -= learning_rate * grads['db1']\n",
    "    W2 -= learning_rate * grads['dW2']\n",
    "    b2 -= learning_rate * grads['db2']\n",
    "    W3 -= learning_rate * grads['dW3']\n",
    "    b3 -= learning_rate * grads['db3']\n",
    "    \n",
    "    # load parameters into running lists\n",
    "    w1s.append(W1[0][0]) # modifies global list\n",
    "    w2s.append(W2[0][0]) # modifies global list\n",
    "    w3s.append(W3[0][0]) # modifies global list\n",
    "    b1s.append(b1[0][0]) # modifies global list\n",
    "    b2s.append(b2[0][0]) # modifies global list\n",
    "    b3s.append(b3[0][0]) # modifies global list\n",
    "    \n",
    "    # Store and return parameters\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2, 'W3':W3,'b3':b3}\n",
    "    return model\n",
    "def predict(model, x):\n",
    "    # Do forward pass\n",
    "    c = forward_prop(model,x)\n",
    "    #get y_hat\n",
    "    y_hat = c['a3']\n",
    "    # plotArr.append([x, y_hat]) #added to make plot\n",
    "    return y_hat\n",
    "def calc_accuracy(model,x,y):\n",
    "    # Get total number of examples\n",
    "    m = y.shape[0]\n",
    "    # Do a prediction with the model\n",
    "    pred = predict(model,x)\n",
    "    # Ensure prediction and truth vector y have the same shape\n",
    "    pred = pred.reshape(y.shape)\n",
    "    # Calculate the number of wrong examples\n",
    "    error = np.sum(np.abs(pred-y))\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100\n",
    "def train(model,X_,y_,learning_rate, epochs=2001, print_loss=False):\n",
    "    # Gradient descent. Loop over epochs\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        # Forward propagation\n",
    "        cache = forward_prop(model,X_)\n",
    "        #a1, probs = cache['a1'],cache['a2']\n",
    "        # Backpropagation\n",
    "        \n",
    "        grads = backward_prop(model,cache,y_)\n",
    "        # Gradient descent parameter update\n",
    "        # Assign new parameters to the model\n",
    "        model = update_parameters(model=model,grads=grads,learning_rate=learning_rate)\n",
    "        # it is at this point in the training that the weights get added to the lists\n",
    "    \n",
    "        a3 = cache['a3']\n",
    "        thisLoss = mse_loss(y_,a3) # set loss function here\n",
    "        losses.append(thisLoss) # modifies global list\n",
    "        y_hat = predict(model,X_) # getting rid of this because it's wrong\n",
    "        y_true = y_.argmax(axis=1)\n",
    "        accur = accuracy_score(a3,train_labels)\n",
    "        train_accuracies.append(accur) # modifies global list\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            placeholderVar = accuracy_score(a3, train_labels)\n",
    "            test_accuracy = accuracyOfModel(model, test_data, test_labels)\n",
    "            test_accuracies.append(test_accuracy) # modifies global list\n",
    "            test_num.append(i)\n",
    "        #Printing loss & accuracy every 100 iterations\n",
    "        if print_loss and i % 300==0:\n",
    "            print('Loss after iteration',i,':',thisLoss)\n",
    "            print('Train Accuracy after iteration',i,':',accur*100,'%')\n",
    "            print('Test Accuracy after iteration',i,':',test_accuracy*100,'%')\n",
    "    return model\n",
    "\n",
    "# TESTING PHASE\n",
    "# test the accuracy of any model\n",
    "def accuracyOfModel(_model, _testData, _testLabels):\n",
    "    y_pred = predict(_model,_testData) # make predictions on test data\n",
    "    y_true = _testLabels # get usable info from labels\n",
    "    return accuracy_score(y_pred, y_true)\n",
    "\n",
    "def accuracy_score(_outputNodes, _labels):\n",
    "    for i in range(len(_outputNodes)-1):\n",
    "        if _outputNodes[i][0]>.5:\n",
    "            _outputNodes[i]=[1,0]\n",
    "        else:\n",
    "            _outputNodes[i]=[0,1]\n",
    "    numWrong = np.count_nonzero(np.subtract(_outputNodes,_labels))/2\n",
    "    return (len(_outputNodes)-numWrong)/len(_outputNodes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 0.7419660983580258\n",
      "Train Accuracy after iteration 0 : 50.719324416576065 %\n",
      "Test Accuracy after iteration 0 : 51.182018153776134 %\n"
     ]
    }
   ],
   "source": [
    "# plotArr = []\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "test_num = []\n",
    "w1s = []\n",
    "w2s = []\n",
    "w3s = []\n",
    "b1s = []\n",
    "b2s = []\n",
    "b3s = []\n",
    "\n",
    "np.random.seed(0)\n",
    "# This is what we return at the end\n",
    "model = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model = train(model,train_data,train_labels,learning_rate=0.01,epochs=2201,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.scatter(test_num, test_accuracies, label=\"Test Accuracy\", s=16, color=\"green\")\n",
    "plt.legend()\n",
    "plt.title(\"Network Loss and Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w1s, label=\"Weight 1\")\n",
    "plt.plot(w2s, label=\"Weight 2\")\n",
    "plt.plot(w3s, label=\"Weight 3\")\n",
    "plt.plot(b1s, label=\"Bias 1\")\n",
    "plt.plot(b2s, label=\"Bias 2\")\n",
    "plt.plot(b3s, label=\"Bias 3\")\n",
    "plt.legend()\n",
    "plt.title(\"Weights and Biases for Eeach Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "print(\"Weight 1: \\n\", W1)\n",
    "print(\"Weight 2: \\n\", W2)\n",
    "print(\"Weight 3: \\n\", W3)\n",
    "print(\"Bias 1: \\n\", b1)\n",
    "print(\"Bias 2: \\n\", b2)\n",
    "print(\"Bias 3: \\n\", b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Output node 2 vs Output node 1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of output node 2 vs output node 1\n",
    "# get weights and biases\n",
    "W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "\n",
    "diffArray = []\n",
    "\n",
    "plotX = []\n",
    "plotY = []\n",
    "\n",
    "inputArr = []\n",
    "outputArr = []\n",
    "for i in range(len(test_data)-1):\n",
    "    _a0 = test_data[i]\n",
    "    diffArray.append(_a0[1]-_a0[0])\n",
    "    inputArr.append(_a0[1])\n",
    "    _z1 = _a0.dot(W1) + b1\n",
    "    # Put it through the first activation function\n",
    "    _a1 = np.tanh(_z1)\n",
    "    # Second linear step\n",
    "    _z2 = _a1.dot(W2) + b2\n",
    "    # Second activation function\n",
    "    _a2 = np.tanh(_z2)\n",
    "    #Third linear step\n",
    "    _z3 = _a2.dot(W3) + b3\n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    _a3 = softmax(_z3)\n",
    "    plotX.append(_a3[0][0])\n",
    "    plotY.append(_a3[0][1])\n",
    "plt.scatter(plotX, plotY)\n",
    "plt.title(\"Output node 2 vs Output node 1\")\n",
    "\n",
    "    # Calculate the point density\n",
    "#     xy = np.vstack([plotX,plotY])\n",
    "#     z = gaussian_kde(xy)(xy)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.scatter(x, y, c=z, s=100, edgecolor='')\n",
    "#     plt.show()\n",
    "\n",
    "#plt.hist(diffArray, bins=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lost muons\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ff10b8782613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Calculate the point density\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmuon_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmuonX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmuonY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmuon_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmuon_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmuon_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m             self._data_covariance = atleast_2d(np.cov(self.dataset, rowvar=1,\n\u001b[1;32m    509\u001b[0m                                                bias=False))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0minv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         raise ValueError('illegal value in %d-th argument of internal '\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    }
   ],
   "source": [
    "# plot muons -- this doesn't work sometimes and we have no idea why\n",
    "muonX = [] # value of \"muon\" output node\n",
    "muonY = [] # value of \"electron\" output node\n",
    "mCount = 0\n",
    "for x, y, l in zip(plotX, plotY, test_labels):\n",
    "    if l[0]==1:\n",
    "        mCount +=1\n",
    "        if(np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y)or x<0 or y<0)!=True:\n",
    "            muonX.append(x)\n",
    "            muonY.append(y)\n",
    "print(mCount-len(muonX), \"lost muons\")\n",
    "# Calculate the point density\n",
    "muon_xy = np.vstack([muonX,muonY])\n",
    "muon_z = gaussian_kde(muon_xy)(muon_xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(muonX, muonY, c=muon_z, s=100, edgecolor='')\n",
    "plt.title(\"Electron Node Value vs Muon Node Value for True Muons\")\n",
    "plt.xlabel(\"Value of Muon Output Node\")\n",
    "plt.ylabel(\"Value of Electron Output Node\")\n",
    "plt.show()\n",
    "#plt.scatter(muonX, muonY)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lost electrons\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8612a8bd017e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Calculate the point density\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mele_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meleX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meleY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mele_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mele_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m             self._data_covariance = atleast_2d(np.cov(self.dataset, rowvar=1,\n\u001b[1;32m    509\u001b[0m                                                bias=False))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0minv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         raise ValueError('illegal value in %d-th argument of internal '\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    }
   ],
   "source": [
    "# plot electrons -- this doesn't work sometime and we have no idea why\n",
    "eleX = [] # value of \"muon\" output node\n",
    "eleY = [] # value of \"electron\" output node\n",
    "eCount = 0\n",
    "for x, y, l in zip(plotX, plotY, test_labels):\n",
    "    if l[0]==0:\n",
    "        eCount +=1\n",
    "        if(np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y) or x<0 or y<0)!=True:\n",
    "            eleX.append(x)\n",
    "            eleY.append(y)\n",
    "print(eCount-len(eleX), \"lost electrons\")\n",
    "# Calculate the point density\n",
    "ele_xy = np.vstack([eleX,eleY])\n",
    "ele_z = gaussian_kde(ele_xy)(ele_xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(eleX, eleY, c=ele_z, s=100, edgecolor='')\n",
    "plt.title(\"Electron Node Value vs Muon Node Value for True Electrons\")\n",
    "plt.xlabel(\"Value of Muon Output Node\")\n",
    "plt.ylabel(\"Value of Electron Output Node\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 differences greater than .75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Difference in Electron and Muon Output Node Values (E-M)')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diffArr = []\n",
    "discardedVals = 0\n",
    "for x, y in zip(plotX, plotY):\n",
    "    if(abs(y-x)<.75):\n",
    "        diffArr.append(y-x)\n",
    "    else:\n",
    "        discardedVals += 1\n",
    "print(discardedVals, \"differences greater than .75\")\n",
    "plt.hist(diffArr, bins=1000)\n",
    "plt.title(\"Difference in Electron and Muon Output Node Values (E-M)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 200\n",
      "Loss after iteration 0 : 0.5224200504467356\n",
      "Train Accuracy after iteration 0 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 0 : 50.307198300927915 %\n",
      "model 400\n",
      "Loss after iteration 0 : 0.5029193001876582\n",
      "Train Accuracy after iteration 0 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 0 : 50.11504133903062 %\n",
      "Loss after iteration 300 : 0.5007030699765981\n",
      "Train Accuracy after iteration 300 : 49.85967485019342 %\n",
      "Test Accuracy after iteration 300 : 49.95069656898688 %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 200 accuracy:  0.501883643902809\n",
      "Model 400 accuracy:  0.4995069656898688\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
