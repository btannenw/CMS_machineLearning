{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this has three hidden layers !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matplotlib is a matlab like plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# SciKitLearn is a useful machine learning utilities library\n",
    "import sklearn\n",
    "# The sklearn dataset module helps generating |datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "# import data\n",
    "from DataExtraction import dataNoMass as data\n",
    "from DataExtraction import dataWithP2\n",
    "from DataExtraction import dataWithP2E2 \n",
    "from DataExtraction import dataWithMass \n",
    "#from DataExtraction import p2E2 as data\n",
    "from DataExtraction import p2NegE2 \n",
    "#from DataExtraction import labels\n",
    "from DataExtraction import labels2D as labels\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any other data manipulations/printing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define softmax\n",
    "def softmax(z):\n",
    "    #Calculate exponent term first\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "\n",
    "# softmax loss\n",
    "def softmax_loss(y,y_hat):\n",
    "    # clipping value \n",
    "    minval = 0.000000000001\n",
    "    # number of samples\n",
    "    m = y.shape[0]\n",
    "    # loss formula, note that np.sum sums up the entire matrix and therefore does the job of two sums from the formula \n",
    "    loss = -1/m * np.sum(y * np.log(y_hat.clip(min=minval)))\n",
    "    return loss\n",
    "\n",
    "# crossentropy loss\n",
    "def crossEntropy_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    if y.all() == 1:\n",
    "        return -1/m * np.sum(np.log(y_hat))\n",
    "    else:\n",
    "        return -1/m * np.sum(np.log(1 - y_hat))\n",
    "\n",
    "# mse loss\n",
    "def mse_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    return np.sum((y_hat - y)**2) / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define derivatives\n",
    "\n",
    "# loss derivative\n",
    "def loss_derivative(y,y_hat):\n",
    "    return (y_hat-y)\n",
    "\n",
    "# tanh derivative\n",
    "def tanh_derivative(x):\n",
    "    return (1 - np.power(x, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propogation\n",
    "def forward_prop(model, a0):\n",
    "    \n",
    "    #Start Forward Propagation\n",
    "    \n",
    "    # Load parameters from model (1)\n",
    "    W1, b1, W2, b2, W3, b3, W4, b4 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3'], model['W4'], model['b4']\n",
    "    \n",
    "    # Do the first Linear step \n",
    "    # Z1 is the input layer x times the dot product of the weights + our bias b\n",
    "    z1 = a0.dot(W1) + b1\n",
    "    \n",
    "    # Put it through the first activation function\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    # Second linear step\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    # Second activation function\n",
    "    a2 = np.tanh(z2)\n",
    "    \n",
    "    # Third linear step\n",
    "    z3 = a2.dot(W3) + b3\n",
    "    \n",
    "    # Third activation function\n",
    "    a3 = np.tanh(z3)\n",
    "    \n",
    "    # Fourth linear step\n",
    "    z4 = a3.dot(W4) + b4\n",
    "    \n",
    "    # For the Third linear activation function we use the softmax function, \n",
    "    # either the sigmoid of softmax should be used for the last layer\n",
    "    a4 = softmax(z4)\n",
    "    \n",
    "    #Store all results in these values\n",
    "    cache = {'a0':a0,'z1':z1,'a1':a1,'z2':z2,'a2':a2,'a3':a3,'z3':z3,'a4':a4,'z4':z4}\n",
    "    return cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward propogation\n",
    "def backward_prop(model, cache, y):\n",
    "\n",
    "    # Load parameters from model (2)\n",
    "    W1, b1, W2, b2, W3, b3, W4, b4 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3'], model['W4'], model['b4']\n",
    "    \n",
    "    # Load forward propagation results\n",
    "    a0,a1,a2,a3,a4 = cache['a0'],cache['a1'],cache['a2'],cache['a3'],cache['a4']\n",
    "    \n",
    "    # Get number of samples\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    #calculate loss derivative with respect to output\n",
    "    \n",
    "    # Calculate loss derivative with respect to output\n",
    "    dz4 = loss_derivative(y=y,y_hat=a4)\n",
    "\n",
    "    # Calculate loss derivative with respect to third layer weights\n",
    "    dW4 = 1/m*(a3.T).dot(dz4) #dW2 = 1/m*(a1.T).dot(dz2) \n",
    "    \n",
    "    # Calculate loss derivative with respect to third layer bias\n",
    "    db4 = 1/m*np.sum(dz4, axis=0)\n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer\n",
    "    dz3 = np.multiply(dz4.dot(W4.T) ,tanh_derivative(a3))\n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer weights\n",
    "    dW3 = 1/m*np.dot(a2.T, dz3)\n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer bias\n",
    "    db3 = 1/m*np.sum(dz3, axis=0)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer\n",
    "    dz2 = np.multiply(dz3.dot(W3.T) ,tanh_derivative(a2))\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer weights\n",
    "    dW2 = 1/m*np.dot(a1.T, dz2)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer bias\n",
    "    db2 = 1/m*np.sum(dz2, axis=0)\n",
    "    \n",
    "    dz1 = np.multiply(dz2.dot(W2.T),tanh_derivative(a1))\n",
    "    \n",
    "    dW1 = 1/m*np.dot(a0.T,dz1)\n",
    "    \n",
    "    db1 = 1/m*np.sum(dz1,axis=0)\n",
    "    \n",
    "    # Store gradients\n",
    "    grads = {'dW4':dW4,'db4':db4, 'dW3':dW3, 'db3':db3, 'dW2':dW2,'db2':db2,'dW1':dW1,'db1':db1}\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PHASE\n",
    "# this takes in the number of nodes in each layer\n",
    "def initialize_parameters(input_dim, l1_dim, l2_dim, l3_dim, output_dim):\n",
    "    \n",
    "    # first layer weights\n",
    "    W1 = 2 * np.random.randn(input_dim, l1_dim) -1\n",
    "    # first layer bias\n",
    "    b1 = np.zeros((1,l1_dim))\n",
    "    \n",
    "    # second layer weights\n",
    "    W2 = 2 * np.random.randn(l1_dim, l2_dim) -1\n",
    "    # second layer bias\n",
    "    b2 = np.zeros((1, l2_dim))\n",
    "    \n",
    "    # third layer weights\n",
    "    W3 = 2 * np.random.randn(l2_dim, l3_dim) -1\n",
    "    # third layer bias\n",
    "    b3 = np.zeros((1, l3_dim))\n",
    "    \n",
    "    # fourth layer weights (output layer)\n",
    "    W4 = 2 * np.random.randn(l3_dim, output_dim)\n",
    "    # fourth layer bias (output layer)\n",
    "    b4 = np.zeros((1, output_dim))\n",
    "    \n",
    "    # package and return model\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2,'W3':W3,'b3':b3, 'W4':W4, 'b4':b4}\n",
    "    return model\n",
    "\n",
    "def update_parameters(model, grads, learning_rate):\n",
    "   # Load parameters from model (3)\n",
    "    W1, b1, W2, b2, W3, b3, W4, b4 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3'], model['W4'], model['b4']\n",
    "    \n",
    "    # update parameters\n",
    "    W1 -= learning_rate * grads['dW1']\n",
    "    b1 -= learning_rate * grads['db1']\n",
    "    W2 -= learning_rate * grads['dW2']\n",
    "    b2 -= learning_rate * grads['db2']\n",
    "    W3 -= learning_rate * grads['dW3']\n",
    "    b3 -= learning_rate * grads['db3']\n",
    "    W4 -= learning_rate * grads['dW4']\n",
    "    b4 -= learning_rate * grads['db4']\n",
    "    \n",
    "    # store and return parameters\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2,'W3':W3,'b3':b3, 'W4':W4, 'b4':b4}\n",
    "    return model\n",
    "\n",
    "# predict\n",
    "def predict(model, x):\n",
    "    # Do forward pass\n",
    "    c = forward_prop(model,x)\n",
    "    #get y_hat\n",
    "    y_hat = c['a4']\n",
    "    # plotArr.append([x, y_hat]) #added to make plot\n",
    "    return y_hat\n",
    "\n",
    "# calculate accuracy\n",
    "def calc_accuracy(model,x,y):\n",
    "    # Get total number of examples\n",
    "    m = y.shape[0]\n",
    "    # Do a prediction with the model\n",
    "    pred = predict(model,x)\n",
    "    # Ensure prediction and truth vector y have the same shape\n",
    "    pred = pred.reshape(y.shape)\n",
    "    # Calculate the number of wrong examples\n",
    "    error = np.sum(np.abs(pred-y))\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100\n",
    "\n",
    "# train\n",
    "# change numbner of epochs here\n",
    "def train(model,X_,y_,learning_rate, epochs=2001, print_loss=False):\n",
    "    # Gradient descent. Loop over epochs\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        # Forward propagation\n",
    "        cache = forward_prop(model,X_)\n",
    "        #a1, probs = cache['a1'],cache['a2']\n",
    "        # Backpropagation\n",
    "        \n",
    "        grads = backward_prop(model,cache,y_)\n",
    "        # Gradient descent parameter update\n",
    "        # Assign new parameters to the model\n",
    "        model = update_parameters(model=model,grads=grads,learning_rate=learning_rate)\n",
    "    \n",
    "        a4 = cache['a4'] \n",
    "        thisLoss = mse_loss(y_,a4) # set loss function here\n",
    "        losses.append(thisLoss)\n",
    "        y_hat = predict(model,X_) # getting rid of this because it's wrong\n",
    "        y_true = y_.argmax(axis=1)\n",
    "        accur = accuracy_score(a4,train_labels)\n",
    "        train_accuracies.append(accur)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            placeholderVar = accuracy_score(a4, train_labels)\n",
    "            test_accuracy = accuracyOfModel(model, test_data, test_labels)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "            test_num.append(i)\n",
    "        #Printing loss & accuracy every 100 iterations\n",
    "        if print_loss and i % 300==0:\n",
    "            print('Loss after iteration',i,':',thisLoss)\n",
    "            print('Train Accuracy after iteration',i,':',accur*100,'%')\n",
    "            print('Test Accuracy after iteration',i,':',test_accuracy*100,'%')\n",
    "    return model\n",
    "    \n",
    "# TESTING PHASE\n",
    "# test the accuracy of any model\n",
    "def accuracyOfModel(_model, _testData, _testLabels):\n",
    "    y_pred = predict(_model,_testData) # make predictions on test data\n",
    "    y_true = _testLabels # get usable info from labels\n",
    "    return accuracy_score(y_pred, y_true)\n",
    "\n",
    "def accuracy_score(_outputNodes, _labels):\n",
    "    for i in range(len(_outputNodes)-1):\n",
    "        if _outputNodes[i][0]>.5:\n",
    "            _outputNodes[i]=[1,0]\n",
    "        else:\n",
    "            _outputNodes[i]=[0,1]\n",
    "    numWrong = np.count_nonzero(np.subtract(_outputNodes,_labels))/2\n",
    "    return (len(_outputNodes)-numWrong)/len(_outputNodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 0.5827150807295448\n",
      "Train Accuracy after iteration 0 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 0 : 49.56385426411469 %\n",
      "Loss after iteration 300 : 0.5000005350893988\n",
      "Train Accuracy after iteration 300 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 300 : 49.56385426411469 %\n",
      "Loss after iteration 600 : 0.49999999477844437\n",
      "Train Accuracy after iteration 600 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 600 : 49.56385426411469 %\n",
      "Loss after iteration 900 : 0.49999999477535534\n",
      "Train Accuracy after iteration 900 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 900 : 49.56385426411469 %\n",
      "Loss after iteration 1200 : 0.49999999477520607\n",
      "Train Accuracy after iteration 1200 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 1200 : 49.56385426411469 %\n",
      "Loss after iteration 1500 : 0.4999999947750566\n",
      "Train Accuracy after iteration 1500 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 1500 : 49.56385426411469 %\n",
      "Loss after iteration 1800 : 0.4999999947749073\n",
      "Train Accuracy after iteration 1800 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 1800 : 49.56385426411469 %\n",
      "Loss after iteration 2100 : 0.499999994774758\n",
      "Train Accuracy after iteration 2100 : 50.0012641905388 %\n",
      "Test Accuracy after iteration 2100 : 49.56385426411469 %\n"
     ]
    }
   ],
   "source": [
    "# plotArr = []\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "test_num = []\n",
    "np.random.seed(0)\n",
    "# This is what we return at the end\n",
    "model = initialize_parameters(input_dim=4, l1_dim=7, l2_dim=5, l3_dim=3, output_dim=2)\n",
    "model = train(model,train_data,train_labels,learning_rate=0.01,epochs=2101,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcFPWd//HXZ3pOOeWIIIfgEZVrCIwQvBKJEGNUTIwrigqo6xVijlUXo79oSGSNWU08Y9DFkGhGVKILqy5CPDcROSKiXAqEYwSUQ0BBjpn5/P6o6qFoeqZ7YHp6hnk/H49+TN31qeqa+vT3+63D3B0REZGa5GQ7ABERafiULEREJCUlCxERSUnJQkREUlKyEBGRlJQsREQkJSWLRsLMXjOzq7IdR30yMzezY7Mdh9QtM+sWfre5tZjnm2b2fCbjqg9mdoeZPVHD+IVm9vUDWO4RZrbYzAoOKsAaNOlkYWYrzewTM2sWGXaVmb2W5vx/MLNfZizAAxRu15nZjqM+hN9BuZl1zHYsjVV44t5uZp9HPjdnO64EdwJ3xXsSYv7IzO41s1g4rsbj38y+bmaVCdv7uZkNCscf1A+z8JjcHS5zs5nNMLMT0pnX3Xu6+2tpLDf+eTec72PgVeDqA407lSadLEIx4IfZDqI6FtD3lESY5C8AtgKX1vO60/5V3FCkiLnY3ZtHPnfXW2ApmNlJQCt3n5UwqtjdmwPfAC4B/rUWi12bsL3N3f2tuooZuDuMrTPwCfCHulxu5FMcGfckcE0drWc/OgnBr4Ebzax1spFmdkL4y2CzmS01s38Jh18NjABuDjP8NDMbbWbTIvN+aGbPRPrXmFnfsPtkM5tjZlvDvydHpnvNzO40s78BO4CjE2LqaGYLzOym2m6smf2rmS0Lt2eqmR0ZDjcz+01Y0tpmZu+ZWa9w3NlmtsjMPgt/xd1YzbKPMbNXzGyTmW00syej+zX8xXdjGPtWM5tsZoWR8TeZ2TozW2tmV6SxORcAW4BxwMiEWGJm9lMzWx7GPc/MuoTjeka+04/N7Kfh8H1KiuEv0LKE+P/dzBYA280s18zGRtaxyMy+k2R/L46M7xdu55SE6e43s/uq2a8rzeyWcP5PzezxhP12jpnNN7MtZvZ3M+tTU8xp7Nfouu8ws2fD7+ozM/uHmRVHxp8YHq9bLKhCOS8yrsjM7jGzVeH3/X9mVhRZ/AgzWx0eK7fWEMa3gNerG+nuS4A3gV5m9iegKzDNDqCEZGZ3AqcBD4bzPxgOvy/8/90WHkunpbM8d98B/BnoFRmcb2Z/DPfnQjMriaz/YGoF3gaONrOjDnD+mrl7k/0AK4Ezgb8AvwyHXQW8FnY3A9YAo4Fc4CvARqBHOP4P8fnC/qMJTl45wJHAKqAsMu7TcFybsPuycLkXh/1tw2lfA1YDPcPxeeGwq4DuwAfA1am2K8nwwWH8/YAC4AHgjXDcN4F5QGvAgBOBjuG4dcBpYffhQL9q1nssMCRcdnvgDeC3CXHNDvdNG2AxcG047izgY4J/qmYE/2AOHFvDdv4VuBs4AigH+kfG3QS8Bxwfbk8x0BZoEW7PvwGFYf/Aar7Pr8e/v0j884EuQFE47MJwe3KAi4Dtkf12IfARcFIYw7HAUUDHcLrW4XS5BL8++1eznSuB98P1tgH+xt7j9SvhvAMJSskjw+kLqos5yfKr3c/AHcAe4HsEx+GNwD/D7jxgGfBTIJ/g+PoMOD6c9yGC47ZTGNvJ4bHRLVzno0BR+N3sAk6sJoZngJuqixnoAawHrqzp+K/ue00y/jXgqoRhl4bHT2547KwHCquZv+o4ApoTHMtvRvbnTuDscJ/8BzAr1f9usuOzmmkWAOfV9bnS3ZUsCJJFL4KqjPbsmywuin/JkXl+D9xe3ZdHkFz6AcOBCQQnxxMIEs7UcJrLgNkJ870FjIocrOOSHMD3hjFfnM52JRn+XwTF2Hh/c4ITQTeCf/QPgK8COQnzrSYo3ras5f49H3gnIa5LI/13A4+E3ROBuyLjvkzNJ7GuQCXQN+yfDtwXGb8UGJZkvoujMSWM2+f7JHmyuCLFNs+PrzeM6YfVTPcS8K9h9znAohTf57WR/rOB5WH374BfJEy/FPhaLWJ2YBvBD53455vhuDvY92SWQ/jjIfysjx4vQGk4Tw7wBUFVUeL6uoXr7BwZNhsYXk18M6LbnxDzp8By4JfxOEgvWVQmbO8WoFnkf+2q6uYPp/k02bZFjqOd4TLXA1OBYyL7c2Zk2h7AF6n+d5MsN/6ZlDDN34DLa/N/mu5H1VCAu78P/A8wNmHUUcDAsIi9xcy2EFQ9dahhca8THIynh92vAV8LP/GidLzUEbWK4BdY3Jokyx5B8Ev12Zq3qFr7rNfdPwc2AZ3c/RXgQYJfg5+Y2QQzaxlOegHBCWqVmb1uYUNgIguuyHgqrKraBjwBtEuYbH2kewdBworHFt3mxP2T6DJgsbvPD/ufBC4xs7ywvwvBSSRRdcPTtc/3YmaXR6qAthD88Ihvc03rmsTedpZLgT/VYr2rCPYXBMfovyUco10i4/eLuRr93L115DM92fzuXgmUhcs/ElgTDovG1olgHxRS876u7lhI9ClBCTBZzIe7+zHufltCHKmsTdje1u6+vbqJw+rTxWF12hagFfsf21H/GS6zg7uf5+7R/ZC43YW1qB78z4SYRyaMb0GQROqcksVetxM0kCWesF9P+HKau/t14fhkj+yNJ4vTwu7X2T9ZrCX4J4/qSpAI4pIt+w6CaqQ/W3jlRy3ts14LGojbxtfr7ve7e3+CXztfJqjKwd3nuPsw4EvA88DT1Sx/fBh3b3dvSXAStDRjW0dwkovrmmL6ywnqZ9eb2XqCUlc7gqQGwXd3TJL51pDQBhSxHTgs0p/sR0HV9xLWDT8KjCGoQmxNUF0U3+bqYoBgP/axoF3oHIJkV5PEfbM2so47E47Rw9y9NFnMB6hq3RZcbNE5XP9aoIvtewFG/DjeSPAruLrtr40FBMdjug52e/eZP2yfuBn4F+Dw8HveSvrHdr0IE86xwLuZWL6SRcjdlwGTgRsig/8H+LKZXWZmeeHnJDM7MRz/MfufeF4HziCoHy4jaHg7i+Ck/E44zYvhci8JG0kvIjhB/0+KMPcQ1IM3A/5oNV8llWdmhZFPLkEVwWgz62vB9djjgbfdfWW4XQPDX+bbCf7RK80s38xGmFkrd99DUPSv7hdcC+BzYKuZdSJMNml6GhhlZj3M7DCC5J1UWLI5BhgA9A0/vQjqhi8PJ3sM+IWZHWeBPmbWlmAfdzSzH5lZgZm1MLOB4TzzgbPNrI2ZdQB+lCLmZgQnlg1hXKPZtyHzMYKLJ/qHMRwbb3x0950EJcQ/E1RJrk6xru+bWWczawPcSnCsQpCsrg2/OzOzZmb2bTNL9kv8QPU3s++Gx9CPCNoXZhE0qO4guMgjz4L7A84Fngp/5U8E7jWzIy244GCQHdh9AC8S/NhKV7L/y9pInL8FQZvYBiDXzH4GtEw2Y5YNAFa6e6pS+QFRstjXOIITAADu/hkwlKD9YS1B8fFXBI10ELQB9AiL/8+H83xAcMJ8M+zfBqwA/ubuFeGwTQS/Jv+NoBroZuAcd9+YKkB33w18l6BRd2INCeNFgjrj+OcOd58J/D9gCsEv+WPCbYPg4H+UoMi/Kozr1+G4y4CVYdXStQTVYcn8nKC9ZivwAsGFA2lx95eA3wKvEDSavlLD5COB/3b399x9ffwD3AecE55Q7yVIQC8TJLj/IkjgnxE0wp9L8H1+SJDcIagKepeg3vhl9p6Qq4t5EXAPQXvTx0Bvgjrj+PhnCO4P+DNBw+/zBA3UcZPCeVJVQREu42WCYyleR4+7zyUoET9I8N0tA0alsbxE79q+1+//NjLuvwna7+IXZXzX3feEx+K5BFcrbQQeJqgvXxLOdyPBRQZzgM0E/zu1Pue4+z8IfoAMTDlx4D+A28L/y6RX7gFH2v73WVwQjrsP+J4FV57dT9D29L8EbXqrCH5IpVO1lwk3J8QcPWeMAB7J1IotbBQRkXpmZl2BJUCH8EdFddOtJGhwnVlfsUXWfQfBRQb1eh9LkjiGAte7+/nZjKOhMrMvEdRqfCUstda5RndjkcihICwR/oSgyqbaRCEBd3+ZoGQlSbj7JwSXu2eMkoVIPQsvLPiYoErjrCyHI5IWVUOJiEhKauAWEZGUDplqqHbt2nm3bt2yHYaISKMyb968je7ePtV0h0yy6NatG3Pnzs12GCIijYqZpXVfhqqhREQkJSULERFJSclCRERSOmTaLESk/uzZs4eysjJ27szIzcKSAYWFhXTu3Jm8vLzUEyehZCEitVZWVkaLFi3o1q0bZg3q4auShLuzadMmysrK6N69+wEtQ9VQIlJrO3fupG3btkoUjYSZ0bZt24MqCSpZiMgBUaJoXA72+1KyCG3buYd7Z3zAe2Vbsx2KiEiDo2QR+mJ3Bff/9UPeX6tkIdIYNG9e3VtYJROULEJ5sWBX7C6vzWt8RUSaBiWLUH6ukoVIY7dy5UoGDx5Mnz59+MY3vsHq1cHbap955hl69epFcXExp59+OgALFy5kwIAB9O3blz59+vDhhx9mM/QGL6OXzprZWQSvKIwBj7n7XQnjRxG8uvOjcNCD7v5YOO5u4NsECW0G8EPP4PPU82JB48/uCiULkdr4+bSFLFpbt+9v6nFkS24/t2et5/vBD37AyJEjGTlyJBMnTuSGG27g+eefZ9y4cUyfPp1OnTqxZcsWAB555BF++MMfMmLECHbv3k1FRUWdbsOhJmMlCzOLAQ8RvJ+3B3CxmfVIMulkd+8bfuKJ4mTgFKAP0As4idq9sL3W8lUNJdLovfXWW1xyySUAXHbZZfzf//0fAKeccgqjRo3i0UcfrUoKgwYNYvz48fzqV79i1apVFBUVZS3uxiCTJYsBwDJ3XwFgZk8Bw4BFaczrQCGQDxiQR/BmsYwxM/Jixh6VLERq5UBKAPXtkUce4e233+aFF16gf//+zJs3j0suuYSBAwfywgsvcPbZZ/P73/+ewYMHZzvUBiuTbRadgDWR/rJwWKILzGyBmT1rZl0A3P0t4FVgXfiZ7u6LE2c0s6vNbK6Zzd2wYcNBB5wfy1HJQqQRO/nkk3nqqacAePLJJznttNMAWL58OQMHDmTcuHG0b9+eNWvWsGLFCo4++mhuuOEGhg0bxoIFC7IZeoOX7QbuaUA3d+9D0C4xCcDMjiV4+XhnggQz2MxOS5zZ3Se4e4m7l7Rvn/LdHSnl5eaoZCHSSOzYsYPOnTtXfe69914eeOABHn/8cfr06cOf/vQn7rvvPgBuuukmevfuTa9evTj55JMpLi7m6aefplevXvTt25f333+fyy+/PMtb1LBlshrqI6BLpL8zexuyAXD3TZHex4C7w+7vALPc/XMAM3sJGAS8mbFoCUsWShYijUJlZfL/1VdeeWW/YX/5y1/2GzZ27FjGjh1b53EdqjJZspgDHGdm3c0sHxgOTI1OYGYdI73nAfGqptXA18ws18zyCBq396uGqmt5sRx2l2fsgisRkUYrYyULdy83szHAdIJLZye6+0IzGwfMdfepwA1mdh5QDmwGRoWzPwsMBt4jaOz+X3eflqlY4wpyVbIQEUkmo/dZuPuLwIsJw34W6b4FuCXJfBXANZmMLZm8WA571MAtIrKfbDdwNyj5KlmIiCSlZBGh+yxERJJTsojIz81hl6qhRET2o2QRkRfTfRYijcGmTZvo27cvffv2pUOHDnTq1Kmqf/fu3WktY/To0SxdurTW6z7nnHM49dRTaz1fY6d3cEcU5OawebuShUhD17ZtW+bPnw/AHXfcQfPmzbnxxhv3mcbdcXdycpL/Jn788cdrvd7NmzezYMECCgsLWb16NV27dq198GkoLy8nN7dhnZ5VsojI0+M+RBq1ZcuW0aNHD0aMGEHPnj1Zt24dV199NSUlJfTs2ZNx48ZVTXvqqacyf/58ysvLad26NWPHjqW4uJhBgwbxySefJF3+s88+y/nnn89FF11U9VgRgPXr1zNs2DD69OlDcXExb7/9NkDV3eTFxcWMHj0agEsvvZTnn3++at74S5xmzpzJ17/+dc455xx69+4NwLnnnkv//v3p2bMnjz32WNU8L7zwAv369aO4uJihQ4dSWVnJsccey+bNmwGoqKjg6KOPruqvCw0rdWVZvh73IVJ7L42F9e/V7TI79IZv3ZV6uiSWLFnCH//4R0pKSgC46667aNOmDeXl5Zxxxhl873vfo0ePfR+AvXXrVr72ta9x11138ZOf/ISJEycmvbu7tLSU8ePH06pVK0aMGMHNN98MwPe//32GDBnCmDFjKC8vZ8eOHbz77rv86le/4u9//ztt2rRJ68Q9d+5cFi1aVFVimTRpEm3atGHHjh2UlJRwwQUXsGvXLq677jrefPNNjjrqKDZv3kxOTg4XX3wxf/7znxkzZgzTp0/npJNOok2bNge0D5NRySJCJQuRxu+YY46pShQQnOD79etHv379WLx4MYsW7f/g66KiIr71rW8B0L9/f1auXLnfNGvXrmX16tUMGjSIHj16UFlZyZIlSwB47bXXuOaa4Naw3NxcWrZsySuvvMJFF11UdcJO58Q9aNCgfaq2fvOb31SVdsrKyli+fDlvvfUWZ5xxBkcdddQ+y73yyiuZNGkSABMnTqwqydQVlSwigvss9LgPkVo5wBJApjRr1qyq+8MPP+S+++5j9uzZtG7dmksvvZSdO3fuN09+fn5VdywWo7y8fL9pJk+ezMaNG+nWrRsQlEZKS0v5+c9/DgSvOUhHbm5u1XOtKioq9llXNPaZM2fyxhtvMGvWLIqKijj11FOTxh7XrVs3Dj/8cF599VXeeecdhg4dmlY86VLJIiJ4RLneliVyqNi2bRstWrSgZcuWrFu3junTpx/wskpLS5k5cyYrV65k5cqVzJ49m9LSUgDOOOMMHnnkESBIANu2bWPw4MFMnjy5qvop/rdbt27MmzcPgOeee67aN/Rt3bqVNm3aUFRUxMKFC5kzZw4QPIb91VdfZdWqVfssF4LSxYgRIxg+fHi1DfsHSskiImizUMlC5FDRr18/evTowQknnMDll1/OKaecckDLWb58OevWrduneuu4446jsLCQefPm8eCDDzJ9+nR69+5NSUkJS5Ysobi4mJtvvpnTTz+dvn37ctNNNwFwzTXXMGPGDIqLi3nnnXcoKChIus5vf/vb7Nixgx49enDbbbcxcOBAAI444gh+97vfMWzYMIqLixkxYkTVPN/5znfYunUro0aNOqDtrIll8LXW9aqkpMTnzp17UMv49fQlPPL6CpaPP7uOohI5NC1evJgTTzwx22FIglmzZnHLLbfw6quvJh2f7Hszs3nuXpJ0hgi1WUTkx2JUVDoVlU4sJ736RxGRhuDOO+9kwoQJ+1zSW5dUDRWRlxskCF0+KyKNza233sqqVasYNGhQRpavZBGRHwt2h548KyKyLyWLiPzcMFnoXgsRkX0oWUTESxaqhhIR2ZeSRUReTCULEZFklCwi4tVQKlmINGx18YhyCB6LsX79+mrH7969mzZt2nDbbbfVRdiNmpJFRDxZ6AVIIg1b/BHl8+fP59prr+XHP/5xVX/00R2ppEoW06dPp0ePHkyePLkuwq5WsseLNDRKFhH5qoYSafQmTZrEgAED6Nu3L9dffz2VlZWUl5dz2WWX0bt3b3r16sX999/P5MmTmT9/PhdddFG1JZLS0lJ+8pOf0KFDB2bPnl01/O2332bQoEEUFxczcOBAduzYQXl5OT/+8Y/p1asXffr04eGHHwagc+fObNmyBQhumjvzzDMBuO2226ruKh81ahTLly/ntNNO4ytf+Qr9+/evesw5wPjx4+nduzfFxcXceuutLF26lJNOOqlq/OLFixkwYEBG9mecbsqL2FsNdWjc1S7SUKz4dAXnlp7L0o1LOb7d8Uy7eBpHH350na/n/fff57nnnuPvf/87ubm5XH311Tz11FMcc8wxbNy4kffeCx6lvmXLFlq3bs0DDzzAgw8+SN++ffdb1o4dO3jttdeqSh+lpaUMGDCAnTt3Mnz4cKZMmUK/fv3YunUrBQUFPPzww6xdu5Z3332XWCyW1iPJlyxZwhtvvEFhYSE7duxgxowZFBYWsmTJEkaOHMnbb7/NtGnTeOmll5g9ezZFRUVs3ry56plR77//Pr169eLxxx+v86fMJlLJIkIN3CKZcW7puSzZuIQKr2DJxiWcW3puRtYzc+ZM5syZQ0lJCX379uX1119n+fLlHHvssSxdupQbbriB6dOn06pVq5TLmjp1KkOGDKGwsJALL7yQKVOmUFlZyeLFi+natSv9+vUDoFWrVsRiMWbOnMm1115LLBYD0nsk+bBhwygsLARg165dXHnllfTq1Yvhw4dXPUp95syZXHHFFRQVFe2z3CuvvJLHH3+c8vJynnnmGS6++OLa77BaUMkiQg3cIpmxdONSKj34v6r0SpZurP27r9Ph7lxxxRX84he/2G/cggULeOmll3jooYeYMmUKEyZMqHFZpaWlzJo1q+qR5Bs2bOD111+ndevWtYop+kjyxEeMRx9Jfs8999ClSxeeeOIJ9uzZU/UGvepceOGFjB8/nlNOOYVBgwbVOq7aUskiIi8WPO5DDdwidev4dseTY8HpJsdyOL7d8RlZz5lnnsnTTz/Nxo0bgeCqqdWrV7NhwwbcnQsvvJBx48bxj3/8A4AWLVrw2Wef7becLVu2MGvWLMrKyqoeSX7//fdTWlpKjx49WL16ddUytm3bRkVFBUOGDOGRRx6peuR4skeST5kypdrYt27dSseOHTEzJk2aRPwhr0OGDGHixIl88cUX+yz3sMMOY/DgwYwZMybjVVCgZLGPApUsRDJi2sXTOKHdCcQsxgntTmDaxdMysp7evXtz++23c+aZZ9KnTx+GDh3Kxx9/zJo1a6oeFT569GjGjx8PwOjRo7nqqqv2a+CeMmUKQ4YMIS8vr2rY+eefz/PPP09OTg6lpaVcd911Ve/A3rVrF9dccw0dOnSoeuf2008/DcAdd9zB9ddfz0knnVTjlVpjxozhscceo7i4mH/+859Vjy4/55xzOOuss6qq1n7zm99UzTNixAjy8vL4xje+Uaf7MRk9ojxi1abtfO3Xr3HPhcVc0L9zHUUmcujRI8obhrvuuotdu3Zx++23pzW9HlFeR9RmISKNxbnnnsuaNWt45ZVX6mV9ShYReXrqrIg0EtOmZaYqrzpqs4jQU2dF0neoVGE3FQf7fSlZROh9FiLpKSwsZNOmTUoYjYS7s2nTpqp7Og6EqqEi4tVQe8r1DyBSk86dO1NWVsaGDRuyHYqkqbCwkM6dD/zCHSWLiFiOEcsxdofXSYtIcnl5eXTv3j3bYUg9UjVUgvxYDrv2qBpKRCRKySJBYV6O2ixERBIoWSQoyI2pZCEikiCjycLMzjKzpWa2zMzGJhk/ysw2mNn88HNVZFxXM3vZzBab2SIz65bJWOMK8nLYWa42CxGRqIw1cJtZDHgIGAKUAXPMbKq7L0qYdLK7j0myiD8Cd7r7DDNrDtTLz/2CXLVZiIgkymTJYgCwzN1XuPtu4ClgWDozmlkPINfdZwC4++fuviNzoe5VkBtjl0oWIiL7yGSy6ASsifSXhcMSXWBmC8zsWTPrEg77MrDFzP5iZu+Y2a/Dkso+zOxqM5trZnPr6nrvwrwcPaJcRCRBthu4pwHd3L0PMAOYFA7PBU4DbgROAo4GRiXO7O4T3L3E3Uvat29fJwEFJQslCxGRqEwmi4+ALpH+zuGwKu6+yd13hb2PAf3D7jJgfliFVQ48D/TLYKxVCnJz2LlH1VAiIlGZTBZzgOPMrLuZ5QPDganRCcysY6T3PGBxZN7WZhYvLgwGEhvGM6JA1VAiIvvJ2NVQ7l5uZmOA6UAMmOjuC81sHDDX3acCN5jZeUA5sJmwqsndK8zsRuCvZmbAPODRTMUapQZuEZH9ZfTZUO7+IvBiwrCfRbpvAW6pZt4ZQJ9MxpdMYZ4unRURSZTtBu4GRw3cIiL7U7JIoAZuEZH9KVkkKMgNGrj1UhcRkb2ULBIU5AX3/unJsyIieylZJCgI38OtdgsRkb2ULBLESxa6IkpEZC8liwTxkoUauUVE9lKySKBqKBGR/SlZJCjIDauhdBe3iEgVJYsEhXkqWYiIJFKySFBVslADt4hIFSWLBAVhyULv4RYR2UvJIkFVA7dKFiIiVZQsEqiBW0Rkf0oWCdTALSKyPyWLBHtLFkoWIiJxShYJ4g3cu3QHt4hIFSWLBLqDW0Rkf0oWCfJjOZipZCEiEqVkkcDMgrflqWQhIlJFySKJorwYX+xWyUJEJE7JIomivBhfqBpKRKSKkkUShflKFiIiUUoWSRyWH2OnqqFERKooWSRRlBdjh5KFiEgVJYskCtVmISKyDyWLJIryYnoHt4hIhJJFEoepgVtEZB9KFkkU5avNQkQkSskiicI8XQ0lIhKlZJGEbsoTEdlX2snCzE41s9Fhd3sz6565sLLrsPwY5ZXOngo9H0pEBNJMFmZ2O/DvwC3hoDzgiUwFlW2FecELkNRuISISSLdk8R3gPGA7gLuvBVpkKqhsK8oPkoUunxURCaSbLHa7uwMOYGbNMhdS9hWFJQs9eVZEJJBusnjazH4PtDazfwVmAo9mLqzsOiwsWaiRW0QkkFaycPf/BJ4FpgDHAz9z9wdSzWdmZ5nZUjNbZmZjk4wfZWYbzGx++LkqYXxLMyszswfT25y6oTYLEZF95aaawMxiwEx3PwOYke6Cw/keAoYAZcAcM5vq7osSJp3s7mOqWcwvgDfSXWddiVdDqc1CRCSQsmTh7hVApZm1quWyBwDL3H2Fu+8GngKGpTuzmfUHjgBeruV6D1q8gVttFiIigZQli9DnwHtmNoPwiigAd7+hhnk6AWsi/WXAwCTTXWBmpwMfAD929zVmlgPcA1wKnFndCszsauBqgK5du6a5KampzUJEZF/pJou/hJ+6Ng0odfddZnYNMAkYDFwPvOjuZWZW7czuPgGYAFBSUuJ1FVShrobrkbFnAAAQXklEQVQSEdlHWsnC3SeZWT7w5XDQUnffk2K2j4Aukf7O4bDocjdFeh8D7g67BwGnmdn1QHMg38w+d/f9GskzoerSWZUsRESANJOFmX2d4Ff/SsCALmY20t1ranyeAxwXPhbkI2A4cEnCcju6+7qw9zxgMYC7j4hMMwooqa9EAZE2CyULEREg/Wqoe4Ch7r4UwMy+DJQC/aubwd3LzWwMMB2IARPdfaGZjQPmuvtU4AYzOw8oBzYDow54S+pQYa6qoUREotJNFnnxRAHg7h+YWV6qmdz9ReDFhGE/i3Tfwt7nTVW3jD8Af0gzzjqRk2MU5uWwY3d5fa5WRKTBSjdZzDWzx9j78MARwNzMhNQwNC/IZbtKFiIiQPrJ4jrg+0D8Utk3gYczElED0awgl+27VLIQEYH0k0UucJ+73wtVd2cXZCyqBqBZvpKFiEhcug8S/CtQFOkvIniY4CGreUEunytZiIgA6SeLQnf/PN4Tdh+WmZAahmYFMbbvUpuFiAiknyy2m1m/eI+ZlQBfZCakhkFtFiIie6XbZvEj4BkzWxv2dwQuykxIDYOqoURE9qqxZGFmJ5lZB3efA5wATAb2AP8L/LMe4suaZkoWIiJVUlVD/R7YHXYPAn5K8I6KTwkf4HeoalaQy47dFVRW1tnzCUVEGq1U1VAxd98cdl8ETHD3KcAUM5uf2dCyq3lB8MiP7bvLaVGY8mZ1EZFDWqqSRczM4gnlG8ArkXHptnc0Ss0Kgs3TFVEiIqlP+KXA62a2keDqpzcBzOxYYGuGY8uq5mGyULuFiEiKZOHud5rZXwmufnrZ3eMV+DnADzIdXDY1y4+XLJQsRERSViW5+6wkwz7ITDgNx95qKCULEZF0b8prclQNJSKyl5JFNZpFroYSEWnqlCyq0bwwXrLQ1VAiIkoW1WiuNgsRkSpKFtUoyouRY0oWIiKgZFEtM6NZQS6f7VSyEBFRsqhBq6I8tn2xJ9thiIhknZJFDVoV5bFVyUJERMmiJi0L89i2U8lCRETJogYqWYiIBJQsaqBkISISULKoQcuiXCULERGULGrUqiiPnXsq2VWuu7hFpGlTsqhBq6LgDXnbvtC9FiLStClZ1KBlmCxUFSUiTZ2SRQ3iyUKXz4pIU6dkUYNWKlmIiABKFjVqWRhvs1CyEJGmTcmiBipZiIgElCxq0LIoeKeFShYi0tQpWdSgIDdGUV6MLTuULESkaVOySKFNs3w2b9+d7TBERLIqo8nCzM4ys6VmtszMxiYZP8rMNpjZ/PBzVTi8r5m9ZWYLzWyBmV2UyThr0q55PhuVLESkicvN1ILNLAY8BAwByoA5ZjbV3RclTDrZ3cckDNsBXO7uH5rZkcA8M5vu7lsyFW912jYv4JPPdtb3akVEGpRMliwGAMvcfYW77waeAoalM6O7f+DuH4bda4FPgPYZi7QGbZrls+lzlSxEpGnLZLLoBKyJ9JeFwxJdEFY1PWtmXRJHmtkAIB9YnmTc1WY218zmbtiwoa7i3kfb5kGycPeMLF9EpDHIdgP3NKCbu/cBZgCToiPNrCPwJ2C0u1cmzuzuE9y9xN1L2rfPTMGjXbMCdldU8vkuPUxQRJquTCaLj4BoSaFzOKyKu29y911h72NA//g4M2sJvADc6u6zMhhnjdo0ywdQVZSINGmZTBZzgOPMrLuZ5QPDganRCcKSQ9x5wOJweD7wHPBHd382gzGm1LZ5mCy270oxpYjIoStjV0O5e7mZjQGmAzFgorsvNLNxwFx3nwrcYGbnAeXAZmBUOPu/AKcDbc0sPmyUu8/PVLzVade8AFDJQkSatowlCwB3fxF4MWHYzyLdtwC3JJnvCeCJTMaWrqpqKN1rISJNWLYbuBu8eLLQXdwi0pQpWaRQmBejRWEun2zTjXki0nQpWaShY6tC1itZiEgTpmSRhg6tili/VclCRJouJYs0dGxZyDolCxFpwpQs0tChVSEbPt/F7vL9biIXEWkSlCzS0LFVIe7o6bMi0mQpWaShY+siALVbiEiTpWSRho6tCgHUbiEiTZaSRRo6hMlCJQsRaaqULNLQoiCX5gW5fLTli2yHIiKSFUoWaTAzjmp7GCs3bc92KCIiWaFkkaZubZuxcqOShYg0TUoWaerW7jDWfPoFeyp0r4WIND1KFmnq1rYZFZVO2adqtxCRpkfJIk3d2zUDULuFiDRJShZpOqptmCzUbiEiTZCSRZraNc+nRWEuyz75PNuhiIjUOyWLNJkZJ3ZsyeJ127IdiohIvVOyqIUeHVuyeN1nVFR6tkMREalXSha10PPIlnyxp0KN3CLS5ChZ1EKPI1sCsGitqqJEpGlRsqiF477UgvxYDu9/tDXboYiI1Csli1rIz82hd+dWzF65OduhiIjUKyWLWvrq0W1YULaV7bvKsx2KiEi9UbKopYHd21JR6cxb9Wm2QxERqTdKFrXU/6jDyc0x/rZ8Y7ZDERGpN0oWtdSsIJevHt2Wlxd+jLvutxCRpkHJ4gB8q3cH/rlxO0s//izboYiI1AsliwMwtEcHcgymvbs226GIiNQLJYsD0L5FAWcc/yWemr2GXeUV2Q5HRCTjlCwO0OhTurNp+26mzlfpQkQOfUoWB+iUY9vS88iW/Hbmh+zco9KFiBzalCwOkJlx67dP5KMtX/DQq8uyHY6ISEYpWRyEk49px3f7deLBV5fx2tJPsh2OiEjGKFkcpF+e34vjj2jBNX+ax6tLlDBE5NCU0WRhZmeZ2VIzW2ZmY5OMH2VmG8xsfvi5KjJupJl9GH5GZjLOg3FYfi5PXjWQo9s3Z/Qf5nDH1IVs/HxXtsMSEalTlqm7kM0sBnwADAHKgDnAxe6+KDLNKKDE3cckzNsGmAuUAA7MA/q7e7UPZCopKfG5c+fW9Wak7YvdFfzHS4t5YtYq8mI5nHH8lxh84pco7tya7u2akZ+rQpyINDxmNs/dS1JNl5vBGAYAy9x9RRjQU8AwYFGNcwW+Ccxw983hvDOAs4DSDMUKX2yBN359wLMXAeMK4ScDdrNo3Tb++c/tbF1awRvAG0BRXoxmBTHyYjlVn1gO5JiBQQ5G2IlZ0H0gjAOY8YDXJSJZ1bwDJ424vV5Wlclk0QlYE+kvAwYmme4CMzudoBTyY3dfU828nRJnNLOrgasBunbtenDR7tkB8/5wcMsAWgMnA4NywWNORaXjgLtTGdZOBYW5YPh+DqKgpydViTQta/K6A40/WaRjGlDq7rvM7BpgEjA43ZndfQIwAYJqqIOKpOWR8NOPDmoRURZ+VPkkIplyYj2uK5Pnso+ALpH+zuGwKu6+yd3jrcGPAf3TnVdEROpPJpPFHOA4M+tuZvnAcGBqdAIz6xjpPQ9YHHZPB4aa2eFmdjgwNBwmIiJZkLFqKHcvN7MxBCf5GDDR3Rea2ThgrrtPBW4ws/OAcmAzMCqcd7OZ/YIg4QCMizd2i4hI/cvYpbP1LduXzoqINEbpXjqr9lcREUlJyUJERFJSsgit+HQFPR/uSe64XHo+3JMVn65okOMaWjxNYTsaWjxNYTsaWjyNaTsyRW0WoZ4P92TJxiVUeiU5lsMJ7U5g4fULG9y4hhZPU9iOhhZPU9iOhhZPY9qO2lKbRS0t3biUSq8EoNIrWbpxaYMc19DiaQrb0dDiaQrb0dDiaUzbkSlKFqHj2x1PjgW7I8dyOL7d8Q1yXEOLpylsR0OLpylsR0OLpzFtR6YoWYSmXTyNE9qdQMxinNDuBKZdPK1Bjmto8TSF7Who8TSF7Who8TSm7cgUtVmIiDRharMQEZE6o2QhIiIpKVmIiEhKShYiIpKSkoWIiKSkZCEiIikpWYiISEpKFiIiktIhc1OemW0AVtXBotoBG+tgOYci7Zuaaf9UT/umZtncP0e5e/tUEx0yyaKumNncdO5mbIq0b2qm/VM97ZuaNYb9o2ooERFJSclCRERSUrLY34RsB9CAad/UTPuneto3NWvw+0dtFiIikpJKFiIikpKShYiIpKRkETKzs8xsqZktM7Ox2Y4nW8xspZm9Z2bzzWxuOKyNmc0wsw/Dv4eHw83M7g/32QIz65fd6OuWmU00s0/M7P3IsFrvCzMbGU7/oZmNzMa2ZEI1++cOM/soPH7mm9nZkXG3hPtnqZl9MzL8kPvfM7MuZvaqmS0ys4Vm9sNweOM9fty9yX+AGLAcOBrIB94FemQ7rizti5VAu4RhdwNjw+6xwK/C7rOBlwADvgq8ne3463hfnA70A94/0H0BtAFWhH8PD7sPz/a2ZXD/3AHcmGTaHuH/VQHQPfx/ix2q/3tAR6Bf2N0C+CDcB432+FHJIjAAWObuK9x9N/AUMCzLMTUkw4BJYfck4PzI8D96YBbQ2sw6ZiPATHD3N4DNCYNruy++Ccxw983u/ikwAzgr89FnXjX7pzrDgKfcfZe7/xNYRvB/d0j+77n7Onf/R9j9GbAY6EQjPn6ULAKdgDWR/rJwWFPkwMtmNs/Mrg6HHeHu68Lu9cARYXdT3G+13RdNcR+NCatSJsarWWjC+8fMugFfAd6mER8/ShaS6FR37wd8C/i+mZ0eHelB2VjXW6N9UY3fAccAfYF1wD3ZDSe7zKw5MAX4kbtvi45rbMePkkXgI6BLpL9zOKzJcfePwr+fAM8RVBN8HK9eCv9+Ek7eFPdbbfdFk9pH7v6xu1e4eyXwKMHxA01w/5hZHkGieNLd/xIObrTHj5JFYA5wnJl1N7N8YDgwNcsx1Tsza2ZmLeLdwFDgfYJ9Eb8KYyTw32H3VODy8EqOrwJbI0XsQ1Vt98V0YKiZHR5WyQwNhx2SEtqsvkNw/ECwf4abWYGZdQeOA2ZziP7vmZkB/wUsdvd7I6Ma7/GT7asGGsqH4GqEDwiuzLg12/FkaR8cTXA1yrvAwvh+ANoCfwU+BGYCbcLhBjwU7rP3gJJsb0Md749SgqqUPQR1xVceyL4AriBo0F0GjM72dmV4//wp3P4FBCfAjpHpbw33z1LgW5Hhh9z/HnAqQRXTAmB++Dm7MR8/etyHiIikpGooERFJSclCRERSUrIQEZGUlCxERCQlJQsREUlJyUKkFsysIvJE1fl1+ZRUM+sWfYKrSEOSm+0ARBqZL9y9b7aDEKlvKlmI1AEL3gNytwXvApltZseGw7uZ2Svhg/X+amZdw+FHmNlzZvZu+Dk5XFTMzB4N34HwspkVZW2jRCKULERqpyihGuqiyLit7t4beBD4bTjsAWCSu/cBngTuD4ffD7zu7sUE74RYGA4/DnjI3XsCW4ALMrw9ImnRHdwitWBmn7t78yTDVwKD3X1F+AC59e7e1sw2EjzyYk84fJ27tzOzDUBnd98VWUY3gncXHBf2/zuQ5+6/zPyWidRMJQuRuuPVdNfGrkh3BWpXlAZCyUKk7lwU+ftW2P13giepAowA3gy7/wpcB2BmMTNrVV9BihwI/WoRqZ0iM5sf6f9fd49fPnu4mS0gKB1cHA77AfC4md0EbABGh8N/CEwwsysJShDXETzBVaRBUpuFSB0I2yxK3H1jtmMRyQRVQ4mISEoqWYiISEoqWYiISEpKFiIikpKShYiIpKRkISIiKSlZiIhISv8fI6powWPKzo4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.scatter(test_num, test_accuracies, label=\"Test Accuracy\", s=16, color=\"green\")\n",
    "plt.legend()\n",
    "plt.title(\"Network Loss and Accuracy per Epoch (Pt Eta Phi E)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
