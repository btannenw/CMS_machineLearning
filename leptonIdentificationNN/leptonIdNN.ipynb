{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matplotlib is a matlab like plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# SciKitLearn is a useful machine learning utilities library\n",
    "import sklearn\n",
    "# The sklearn dataset module helps generating |datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "# import data\n",
    "from DataExtraction import dataNoMass\n",
    "from DataExtraction import dataWithP2\n",
    "from DataExtraction import dataWithP2E2 \n",
    "from DataExtraction import dataWithMass \n",
    "#from DataExtraction import p2E2 as data\n",
    "from DataExtraction import p2NegE2 as data\n",
    "#from DataExtraction import labels\n",
    "from DataExtraction import labels2D as labels\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y = train_labels\n",
    "# for i in range(5):\n",
    "#     print(y[i])\n",
    "# print(len(y))\n",
    "# print(y.shape)\n",
    "# x = train_data\n",
    "# for i in range(5):\n",
    "#     print(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runSum = 0\n",
    "# for e in train_data:\n",
    "#     runSum+=e\n",
    "# avgE2 = runSum/(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.47057014 1.44852822]\n",
      "[1.37529307 1.37653944]\n",
      "[0.164536   0.16798574]\n",
      "[0.66294606 0.65643949]\n",
      "[1.44284613 1.42079893]\n",
      "bruh\n",
      "[1.75002683 1.75009416]\n",
      "[1.90345077 1.88149124]\n",
      "[0.19035625 0.16807067]\n",
      "[0.49133276 0.49179333]\n",
      "[0.89221778 0.87006578]\n",
      "(39551, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data#/avgE2\n",
    "test_data = test_data#/avgE2\n",
    "#X = train_data\n",
    "test_data\n",
    "for i in range(5): \n",
    "    print(train_data[i])\n",
    "print(\"bruh\")\n",
    "for i in range(5): \n",
    "    print(test_data[i])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "plotArr = []\n",
    "for i in range(5):\n",
    "    print(test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define all our functions\n",
    "\n",
    "def softmax(z):\n",
    "    #Calculate exponent term first\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "# loss functions\n",
    "def softmax_loss(y,y_hat):\n",
    "    # Clipping value\n",
    "    minval = 0.000000000001\n",
    "    # Number of samples\n",
    "    m = y.shape[0]\n",
    "    # Loss formula, note that np.sum sums up the entire matrix and therefore does the job of two sums from the formula\n",
    "    loss = -1/m * np.sum(y * np.log(y_hat.clip(min=minval)))\n",
    "    #loss = -1/m * np.sum(y * np.log(y_hat))\n",
    "    return loss\n",
    "\n",
    "def crossEntropy_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    if y.all() == 1:\n",
    "        return -1/m * np.sum(np.log(y_hat))\n",
    "    else:\n",
    "        return -1/m * np.sum(np.log(1 - y_hat))\n",
    "\n",
    "def mse_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    return np.sum((y_hat - y)**2) / m\n",
    "    \n",
    "def loss_derivative(y,y_hat):\n",
    "    return (y_hat-y)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return (1 - np.power(x, 2))\n",
    "\n",
    "# This is the forward propagation function\n",
    "def forward_prop(model,a0):\n",
    "    \n",
    "    #Start Forward Propagation\n",
    "    \n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2, W3, b3 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3']\n",
    "    \n",
    "    # Do the first Linear step \n",
    "    # Z1 is the input layer x times the dot product of the weights + our bias b\n",
    "    z1 = a0.dot(W1) + b1\n",
    "    \n",
    "    # Put it through the first activation function\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    # Second linear step\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    # Second activation function\n",
    "    a2 = np.tanh(z2)\n",
    "    \n",
    "    #Third linear step\n",
    "    z3 = a2.dot(W3) + b3\n",
    "    \n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    a3 = softmax(z3)\n",
    "    \n",
    "    #Store all results in these values\n",
    "    cache = {'a0':a0,'z1':z1,'a1':a1,'z2':z2,'a2':a2,'a3':a3,'z3':z3}\n",
    "    return cache\n",
    "\n",
    "# This is the BACKWARD PROPAGATION function\n",
    "def backward_prop(model,cache,y):\n",
    "\n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2, W3, b3 = model['W1'], model['b1'], model['W2'], model['b2'],model['W3'],model['b3']\n",
    "    # Load forward propagation results\n",
    "    a0,a1, a2,a3 = cache['a0'],cache['a1'],cache['a2'],cache['a3']\n",
    "    \n",
    "    # Get number of samples\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    # Calculate loss derivative with respect to output\n",
    "    dz3 = loss_derivative(y=y,y_hat=a3)\n",
    "\n",
    "    # Calculate loss derivative with respect to second layer weights\n",
    "    dW3 = 1/m*(a2.T).dot(dz3) #dW2 = 1/m*(a1.T).dot(dz2) \n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer bias\n",
    "    db3 = 1/m*np.sum(dz3, axis=0)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer\n",
    "    dz2 = np.multiply(dz3.dot(W3.T) ,tanh_derivative(a2))\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer weights\n",
    "    dW2 = 1/m*np.dot(a1.T, dz2)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer bias\n",
    "    db2 = 1/m*np.sum(dz2, axis=0)\n",
    "    \n",
    "    dz1 = np.multiply(dz2.dot(W2.T),tanh_derivative(a1))\n",
    "    \n",
    "    dW1 = 1/m*np.dot(a0.T,dz1)\n",
    "    \n",
    "    db1 = 1/m*np.sum(dz1,axis=0)\n",
    "    \n",
    "    # Store gradients\n",
    "    grads = {'dW3':dW3, 'db3':db3, 'dW2':dW2,'db2':db2,'dW1':dW1,'db1':db1}\n",
    "    return grads\n",
    "\n",
    "#TRAINING PHASE\n",
    "def initialize_parameters(nn_input_dim,nn_hdim,nn_output_dim):\n",
    "    # First layer weights\n",
    "    W1 = 2 *np.random.randn(nn_input_dim, nn_hdim) - 1\n",
    "    \n",
    "    # First layer bias\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    \n",
    "    # Second layer weights\n",
    "    W2 = 2 * np.random.randn(nn_hdim, nn_hdim) - 1\n",
    "    \n",
    "    # Second layer bias\n",
    "    b2 = np.zeros((1, nn_hdim))\n",
    "    W3 = 2 * np.random.rand(nn_hdim, nn_output_dim) - 1\n",
    "    b3 = np.zeros((1,nn_output_dim))\n",
    "    \n",
    "    \n",
    "    # Package and return model\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2,'W3':W3,'b3':b3}\n",
    "    return model\n",
    "\n",
    "def update_parameters(model,grads,learning_rate):\n",
    "    # Load parameters\n",
    "    W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "    \n",
    "    # Update parameters\n",
    "    W1 -= learning_rate * grads['dW1']\n",
    "    b1 -= learning_rate * grads['db1']\n",
    "    W2 -= learning_rate * grads['dW2']\n",
    "    b2 -= learning_rate * grads['db2']\n",
    "    W3 -= learning_rate * grads['dW3']\n",
    "    b3 -= learning_rate * grads['db3']\n",
    "    \n",
    "    # Store and return parameters\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2, 'W3':W3,'b3':b3}\n",
    "    return model\n",
    "def predict(model, x):\n",
    "    # Do forward pass\n",
    "    c = forward_prop(model,x)\n",
    "    #get y_hat\n",
    "    y_hat = np.argmax(c['a3'], axis=1)\n",
    "    plotArr.append([x, y_hat]) #added to make plot\n",
    "    return y_hat\n",
    "def calc_accuracy(model,x,y):\n",
    "    # Get total number of examples\n",
    "    m = y.shape[0]\n",
    "    # Do a prediction with the model\n",
    "    pred = predict(model,x)\n",
    "    # Ensure prediction and truth vector y have the same shape\n",
    "    pred = pred.reshape(y.shape)\n",
    "    # Calculate the number of wrong examples\n",
    "    error = np.sum(np.abs(pred-y))\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100\n",
    "def train(model,X_,y_,learning_rate, epochs=2001, print_loss=False):\n",
    "    # Gradient descent. Loop over epochs\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        # Forward propagation\n",
    "        cache = forward_prop(model,X_)\n",
    "        #a1, probs = cache['a1'],cache['a2']\n",
    "        # Backpropagation\n",
    "        \n",
    "        grads = backward_prop(model,cache,y_)\n",
    "        # Gradient descent parameter update\n",
    "        # Assign new parameters to the model\n",
    "        model = update_parameters(model=model,grads=grads,learning_rate=learning_rate)\n",
    "    \n",
    "        a3 = cache['a3']\n",
    "        thisLoss = mse_loss(y_,a3) # set loss function here\n",
    "        losses.append(thisLoss)\n",
    "        y_hat = predict(model,X_)\n",
    "        y_true = y_.argmax(axis=1)\n",
    "        accur = accuracy_score(y_pred=y_hat,y_true=y_true)\n",
    "        train_accuracies.append(accur)\n",
    "        # Pring loss & accuracy every 100 iterations\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            test_accuracy = accuracyOfModel(model, test_data, test_labels)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "            test_num.append(i)\n",
    "        \n",
    "        if print_loss and i % 200==0:\n",
    "            print('Loss after iteration',i,':',thisLoss)\n",
    "            print('Train Accuracy after iteration',i,':',accur*100,'%')\n",
    "            print('Test Accuracy after iteration',i,':',test_accuracy*100,'%')\n",
    "            #losses.append(accuracy_score(y_pred=y_hat,y_true=y_true)*100)\n",
    "           # print('Input value', i,':', X)\n",
    "           # print('Weights:', W1, W2, W3)\n",
    "           # print('Output value', i, ':', y_hat)\n",
    "           # print('y_ length', len(y_))\n",
    "            print(y_hat.shape)\n",
    "    return model\n",
    "\n",
    "# TESTING PHASE\n",
    "# test the accuracy of any model\n",
    "def accuracyOfModel(_model, _testData, _testLabels):\n",
    "    y_pred = predict(_model,_testData) # make predictions on test data\n",
    "    y_true = _testLabels.argmax(axis=1) # get usable info from labels\n",
    "    return accuracy_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 0.7419660983580258\n",
      "Train Accuracy after iteration 0 : 50.80781775429193 %\n",
      "Test Accuracy after iteration 0 : 51.182018153776134 %\n",
      "(39551,)\n",
      "Loss after iteration 200 : 0.49416346858891563\n",
      "Train Accuracy after iteration 200 : 52.929129478394984 %\n",
      "Test Accuracy after iteration 200 : 53.030264721498824 %\n",
      "(39551,)\n",
      "Loss after iteration 400 : 0.4857973429963413\n",
      "Train Accuracy after iteration 400 : 54.911380243230255 %\n",
      "Test Accuracy after iteration 400 : 55.181917018533035 %\n",
      "(39551,)\n",
      "Loss after iteration 600 : 0.46432872000316106\n",
      "Train Accuracy after iteration 600 : 67.75302773634041 %\n",
      "Test Accuracy after iteration 600 : 67.98816717655684 %\n",
      "(39551,)\n",
      "Loss after iteration 800 : 0.4527062437330347\n",
      "Train Accuracy after iteration 800 : 74.98419761826503 %\n",
      "Test Accuracy after iteration 800 : 75.27748982326617 %\n",
      "(39551,)\n",
      "Loss after iteration 1000 : 0.4444359497581548\n",
      "Train Accuracy after iteration 1000 : 79.25210487724709 %\n",
      "Test Accuracy after iteration 1000 : 79.42909155267883 %\n",
      "(39551,)\n",
      "Loss after iteration 1200 : 0.43658228268040644\n",
      "Train Accuracy after iteration 1200 : 84.65778362114737 %\n",
      "Test Accuracy after iteration 1200 : 84.779145912872 %\n",
      "(39551,)\n",
      "Loss after iteration 1400 : 0.4277810301386631\n",
      "Train Accuracy after iteration 1400 : 92.75618821268742 %\n",
      "Test Accuracy after iteration 1400 : 92.93570326919674 %\n",
      "(39551,)\n",
      "Loss after iteration 1600 : 0.4172432758515243\n",
      "Train Accuracy after iteration 1600 : 97.77249627063792 %\n",
      "Test Accuracy after iteration 1600 : 97.83064903542262 %\n",
      "(39551,)\n",
      "Loss after iteration 1800 : 0.4056546838137022\n",
      "Train Accuracy after iteration 1800 : 98.08348714318223 %\n",
      "Test Accuracy after iteration 1800 : 98.10118581072538 %\n",
      "(39551,)\n",
      "Loss after iteration 2000 : 0.39378693434609974\n",
      "Train Accuracy after iteration 2000 : 98.19726429167403 %\n",
      "Test Accuracy after iteration 2000 : 98.20737781598442 %\n",
      "(39551,)\n",
      "Loss after iteration 2200 : 0.38143591340338917\n",
      "Train Accuracy after iteration 2200 : 98.27817248615712 %\n",
      "Test Accuracy after iteration 2200 : 98.27311572400193 %\n",
      "(39551,)\n"
     ]
    }
   ],
   "source": [
    "plotArr = []\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "test_num = []\n",
    "np.random.seed(0)\n",
    "# This is what we return at the end\n",
    "model = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model = train(model,train_data,train_labels,learning_rate=0.01,epochs=2201,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.scatter(test_num, test_accuracies, label=\"Test Accuracy\", s=16, color=\"green\")\n",
    "plt.legend()\n",
    "plt.title(\"Network Loss and Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.75002683 1.75009416]\n",
      "[1.90345077 1.88149124]\n",
      "[0.19035625 0.16807067]\n",
      "[0.49133276 0.49179333]\n",
      "[0.89221778 0.87006578]\n",
      "[0.44086735 0.44105678]\n",
      "[1.98645791 1.96451417]\n",
      "[0.79652026 0.79685403]\n",
      "[1.78614203 1.78704311]\n",
      "[1.84022166 1.81825009]\n",
      "39551\n"
     ]
    }
   ],
   "source": [
    "for i in range (10):\n",
    "    print(test_data[i])\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get weights and biases\n",
    "W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "\n",
    "diffArray = []\n",
    "\n",
    "plotX = []\n",
    "plotY = []\n",
    "\n",
    "inputArr = []\n",
    "outputArr = []\n",
    "for i in range(len(test_data)-1):\n",
    "    _a0 = test_data[i]\n",
    "    #print(_a0, _a0[1]-_a0[0])\n",
    "    diffArray.append(_a0[1]-_a0[0])\n",
    "    inputArr.append(_a0[1])\n",
    "    _z1 = _a0.dot(W1) + b1\n",
    "    # Put it through the first activation function\n",
    "    _a1 = np.tanh(_z1)\n",
    "    # Second linear step\n",
    "    _z2 = _a1.dot(W2) + b2\n",
    "    # Second activation function\n",
    "    _a2 = np.tanh(_z2)\n",
    "    #Third linear step\n",
    "    _z3 = _a2.dot(W3) + b3\n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    _a3 = softmax(_z3)\n",
    "    plotX.append(_a3[0][0])\n",
    "    plotY.append(_a3[0][1])\n",
    "plt.scatter(plotX, plotY)\n",
    "    # Calculate the point density\n",
    "#     xy = np.vstack([plotX,plotY])\n",
    "#     z = gaussian_kde(xy)(xy)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.scatter(x, y, c=z, s=100, edgecolor='')\n",
    "#     plt.show()\n",
    "\n",
    "#plt.hist(diffArray, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot muons, this doesn't work right now and we have no idea why\n",
    "muonX = [] # value of \"muon\" output node\n",
    "muonY = [] # value of \"electron\" output node\n",
    "mCount = 0\n",
    "for x, y, l in zip(plotX, plotY, test_labels):\n",
    "    if l[0]==1:\n",
    "        mCount +=1\n",
    "        if(np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y)or x<0 or y<0)!=True:\n",
    "            muonX.append(x)\n",
    "            muonY.append(y)\n",
    "print(mCount-len(muonX), \"lost muons\")\n",
    "# Calculate the point density\n",
    "muon_xy = np.vstack([muonX,muonY])\n",
    "muon_z = gaussian_kde(muon_xy)(muon_xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(muonX, muonY, c=muon_z, s=100, edgecolor='')\n",
    "plt.title(\"Electron Node Value vs Muon Node Value for True Muons\")\n",
    "plt.xlabel(\"Value of Muon Output Node\")\n",
    "plt.ylabel(\"Value of Electron Output Node\")\n",
    "plt.show()\n",
    "#plt.scatter(muonX, muonY)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot electrons\n",
    "eleX = [] # value of \"muon\" output node\n",
    "eleY = [] # value of \"electron\" output node\n",
    "eCount = 0\n",
    "for x, y, l in zip(plotX, plotY, test_labels):\n",
    "    if l[0]==0:\n",
    "        eCount +=1\n",
    "        if(np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y) or x<0 or y<0)!=True:\n",
    "            eleX.append(x)\n",
    "            eleY.append(y)\n",
    "print(eCount-len(eleX), \"lost electrons\")\n",
    "# Calculate the point density\n",
    "ele_xy = np.vstack([eleX,eleY])\n",
    "ele_z = gaussian_kde(ele_xy)(ele_xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(eleX, eleY, c=ele_z, s=100, edgecolor='')\n",
    "plt.title(\"Electron Node Value vs Muon Node Value for True Electrons\")\n",
    "plt.xlabel(\"Value of Muon Output Node\")\n",
    "plt.ylabel(\"Value of Electron Output Node\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffArr = []\n",
    "discardedVals = 0\n",
    "for x, y in zip(plotX, plotY):\n",
    "    if(abs(y-x)<.75):\n",
    "        diffArr.append(y-x)\n",
    "    else:\n",
    "        discardedVals += 1\n",
    "print(discardedVals, \"differences greater than .75\")\n",
    "plt.hist(diffArr, bins=1000)\n",
    "plt.title(\"Difference in Electron and Muon Output Node Values (E-M)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some models with different numbers of epochs\n",
    "print(\"model 200\")\n",
    "model_200 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model_200 = train(model_200,train_data,train_labels,learning_rate=0.01,epochs=201,print_loss=True)\n",
    "# model_300 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "# model_300 = train(model_300,train_data,train_labels,learning_rate=0.01,epochs=301,print_loss=True)\n",
    "print(\"model 400\")\n",
    "model_400 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model_400 = train(model_400,train_data,train_labels,learning_rate=0.01,epochs=401,print_loss=True)\n",
    "# model_500 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "# model_500 = train(model_500,train_data,train_labels,learning_rate=0.01,epochs=501,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model 200 accuracy: \", accuracyOfModel(model_200, test_data, test_labels))\n",
    "print(\"Model 400 accuracy: \", accuracyOfModel(model_400, test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
